{"posts":[{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"_id":"66c6db287be0bfa794361b0c","createdAt":"2024-08-22T06:31:04.131Z","updatedAt":"2024-08-22T06:31:04.131Z","views":0,"isActive":true,"hasLatex":true,"popularity":7006.6014,"discussionScore":0,"enableToc":true,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"disableComments":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"slugOverridden":false,"tweetOptions":{"enabled":false},"title":"The CAP Theorem and MongoDB: Navigating Trade-offs in Distributed Databases","cuid":"cm04wmbpe000d09kt6ohmftyp","dateAdded":"2024-08-22T06:31:04.130Z","isCoverAttributionHidden":false,"coverImageAttribution":"","coverImagePhotographer":"","stickCoverToBottom":false,"slug":"the-cap-theorem-and-mongodb-navigating-trade-offs-in-distributed-databases","toc":[[{"id":"6dec2fa9-4a1d-433f-9812-9f65874e8285","level":3,"previousLevel":null,"parentId":null,"slug":"what-is-distributed-system","title":"What is Distributed System?"}],[{"id":"df3fbd04-bb0b-42c2-b74a-ac3b6b3d041d","level":3,"previousLevel":3,"parentId":null,"slug":"key-characteristics-of-distributed-systems","title":"Key Characteristics of Distributed Systems"}],[{"id":"96930132-e2df-4e01-b2bc-9ac2fd3daab5","level":3,"previousLevel":3,"parentId":null,"slug":"challenges-in-distributed-systems","title":"Challenges in Distributed Systems"}],[{"id":"326e7c4d-1419-4a31-93b7-85089af26390","level":3,"previousLevel":3,"parentId":null,"slug":"what-is-the-cap-theorem","title":"What is the CAP Theorem?"}],[{"id":"7a3f8353-5608-404d-8b1b-24c8b9e6217a","level":3,"previousLevel":3,"parentId":null,"slug":"what-is-consistency-availability-amp-partition-tolerance","title":"What is Consistency , Availability &amp; Partition Tolerance??!!"}],[{"id":"068ea5cd-2e88-40a6-9e57-d14ff4c45d3e","level":3,"previousLevel":3,"parentId":null,"slug":"why-only-two-whats-the-problem-with-three","title":"Why Only Two? What's the problem with Three??!!"}],[{"id":"0b0a2bf8-d6b7-484b-90a3-37ec104fbe72","level":2,"previousLevel":3,"parentId":null,"slug":"mongodb-and-the-cap-theorem","title":"MongoDB and the CAP Theorem"}],[{"id":"35a01005-73de-4bd3-ac2a-f8874d1c40a6","level":2,"previousLevel":2,"parentId":null,"slug":"but-can-i-change-it","title":"But Can I Change it??!!"}],[{"id":"e3fc9d4b-9f56-4efe-977e-cf08dde82f38","level":4,"previousLevel":2,"parentId":"35a01005-73de-4bd3-ac2a-f8874d1c40a6","slug":"optimizing-for-consistency-and-partition-tolerance","title":"Optimizing for Consistency and Partition Tolerance"}],[{"id":"ad97a9e6-065a-455a-9f74-0d9a8de8070d","level":4,"previousLevel":4,"parentId":"35a01005-73de-4bd3-ac2a-f8874d1c40a6","slug":"2-optimizing-for-availability-and-partition-tolerance","title":"2. Optimizing for Availability and Partition Tolerance"}]],"content":"<p>In the world of distributed databases, the CAP theorem, also known as Brewer's theorem, provides a foundational framework for understanding the trade-offs between different system characteristics. Before diving into CAP Theorem we need some knowledge about distributed system. Let's talk about that first.</p>\n<h3 id=\"heading-what-is-distributed-system\">What is Distributed System?</h3>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1724304518545/3b573207-5138-4c2e-9d35-1e5ae3d40260.jpeg\" alt class=\"image--center mx-auto\" /></p>\n<p>A distributed system is a collection of independent computers that appear to the users of the system as a single coherent system. These systems are designed to share resources and coordinate their actions by passing messages. Distributed systems are ubiquitous in modern computing, powering everything from large-scale web applications to cloud services and IoT networks.</p>\n<h3 id=\"heading-key-characteristics-of-distributed-systems\"><strong>Key Characteristics of Distributed Systems</strong></h3>\n<ol>\n<li><p><strong>Scalability</strong>: Distributed systems are designed to handle increasing loads by adding more resources (e.g., servers, storage) to the system. This can be achieved through horizontal scaling (adding more machines) or vertical scaling (upgrading existing machines).</p>\n</li>\n<li><p><strong>Fault Tolerance</strong>: Distributed systems are designed to continue functioning even if some components fail. This is achieved through redundancy, replication, and failover mechanisms.</p>\n</li>\n<li><p><strong>Concurrency</strong>: Distributed systems often need to handle multiple tasks simultaneously. Concurrency control mechanisms ensure that these tasks do not interfere with each other, maintaining data consistency and integrity.</p>\n</li>\n<li><p><strong>Transparency</strong>: Users and applications should interact with the distributed system as if it were a single, coherent system. This transparency hides the complexity of the underlying distributed architecture.</p>\n</li>\n<li><p><strong>Heterogeneity</strong>: Distributed systems often consist of diverse hardware and software components. The system must be able to integrate and manage these heterogeneous elements seamlessly.</p>\n</li>\n</ol>\n<h3 id=\"heading-challenges-in-distributed-systems\"><strong>Challenges in Distributed Systems</strong></h3>\n<ol>\n<li><p><strong>Network Latency</strong>: Communication between nodes in a distributed system can introduce delays, which can affect performance and consistency.</p>\n</li>\n<li><p><strong>Partial Failures</strong>: Unlike centralized systems, distributed systems can experience partial failures where some components fail while others continue to operate. Handling these failures gracefully is a significant challenge.</p>\n</li>\n<li><p><strong>Consistency</strong>: Ensuring that all nodes in a distributed system have a consistent view of the data is complex, especially in the presence of network partitions and failures.</p>\n</li>\n<li><p><strong>Security</strong>: Distributed systems are often more vulnerable to security threats due to their distributed nature. Ensuring secure communication and data integrity is crucial.</p>\n</li>\n<li><p><strong>Coordination</strong>: Coordinating the actions of multiple nodes to achieve a common goal can be complex and requires sophisticated algorithms and protocols.</p>\n</li>\n</ol>\n<p>Databases like <strong>MongoDB</strong>, Cassandra, and CockroachDB are designed to handle distributed data storage and retrieval, providing scalability and fault tolerance.</p>\n<h3 id=\"heading-what-is-the-cap-theorem\">What is the CAP Theorem?</h3>\n<blockquote>\n<p>In distributed systems, you can only have two out of Consistency, Availability, and Partition Tolerance. You have to choose which two matter most to you</p>\n</blockquote>\n<h3 id=\"heading-what-is-consistency-availability-amp-partition-tolerance\">What is Consistency , Availability &amp; Partition Tolerance??!!</h3>\n<ul>\n<li><p><strong>Consistency</strong>: Ensuring that every read returns the most recent write means that the system must synchronize and agree on the latest state of the data across all nodes. This requires coordination and communication between nodes to ensure that all updates are seen by all nodes.</p>\n</li>\n<li><p><strong>Availability</strong>: To be available, a system must respond to every request, even if it cannot guarantee that the data returned is the most recent. This means that the system continues to serve requests without interruption, which often involves accepting reads and writes even when there might be discrepancies between nodes.</p>\n</li>\n<li><p><strong>Partition Tolerance</strong>: A distributed system is subject to network failures or partitions, where some nodes cannot communicate with others. Partition tolerance means the system must continue operating even when parts of it are isolated. However, maintaining this while also ensuring consistency and availability poses significant challenges.</p>\n</li>\n</ul>\n<h3 id=\"heading-why-only-two-whats-the-problem-with-three\">Why Only Two? What's the problem with Three??!!</h3>\n<p>Here’s why achieving all three properties simultaneously is typically infeasible:</p>\n<ol>\n<li><p><strong>Consistency and Partition Tolerance (CP)</strong></p>\n<ul>\n<li><p>When focusing on <strong>Consistency</strong> and <strong>Partition Tolerance</strong>, the system must ensure that all nodes have the same data despite network partitions. This often means that if a partition occurs, the system might sacrifice <strong>Availability</strong>. For example, during a network partition, if nodes cannot communicate to agree on the latest state of the data, the system may reject requests (both reads and writes) to avoid serving outdated or inconsistent data.</p>\n</li>\n<li><p><strong>Long Story Short</strong> : <strong>Network partition</strong> happened so one node can't communicate with other but i still need the latest data, but server doesn't have right now. so it will reject the request hence sacrificing the <strong>Availability</strong>.</p>\n</li>\n</ul>\n</li>\n<li><p><strong>Availability and Partition Tolerance (AP)</strong></p>\n<ul>\n<li><p>For <strong>Availability</strong> and <strong>Partition Tolerance</strong>, the system must continue to operate and serve requests even if some nodes are isolated. This might lead to temporary inconsistencies if nodes are operating independently of each other. To maintain availability, the system might serve stale or conflicting data because it cannot wait to ensure all nodes have synchronized before responding to requests.</p>\n</li>\n<li><p><strong>Long Story Short</strong> : <strong>Network partition</strong> happened so one node can't communicate with other but i still need the latest data, As we configured as AP system so it will give me the latest data from that node even all the node is not synchronized and this data you get from the server might be rolled back. Hence sacrificing the <strong>Consistency</strong>.</p>\n</li>\n</ul>\n</li>\n<li><p><strong>Consistency and Availability (CA)</strong></p>\n<ul>\n<li><p>To ensure <strong>Consistency</strong> and <strong>Availability</strong>, the system must respond to every request with the most recent data. However, this is typically not feasible in the presence of network partitions. To achieve consistency and availability, the system needs to coordinate all nodes, but network partitions can prevent nodes from communicating, making it impossible to maintain both properties simultaneously.</p>\n</li>\n<li><p><strong>Long Story Short</strong> : If you want consistent data and available at the same time in all nodes. you have to make sure that the do not stop communicating with each other. Because if network partition occurs then your nodes can't be consistent or available. So you need consistency and availability sacrifice the chance of partition [<em>in real life it is not practical by the way.</em>]</p>\n</li>\n</ul>\n</li>\n</ol>\n<p>    <img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1724306663598/dd43e476-d26f-4576-9c91-3f3486896bf0.jpeg\" alt class=\"image--center mx-auto\" /></p>\n<h2 id=\"heading-mongodb-and-the-cap-theorem\">MongoDB and the CAP Theorem</h2>\n<p>MongoDB is a popular NoSQL database designed for high performance and flexibility. To understand how MongoDB aligns with the CAP theorem, let's explore how it balances consistency, availability, and partition tolerance:</p>\n<ol>\n<li><p><strong>Consistency</strong>: MongoDB offers strong consistency by default. In a replica set, writes are acknowledged only after they are written to the primary and replicated to the majority of the secondary nodes. This ensures that all reads will see the most recent write once the write is acknowledged.</p>\n</li>\n<li><p><strong>Availability</strong>: MongoDB aims for high availability by using replica sets. If the primary node fails, one of the secondary nodes is automatically promoted to primary, ensuring continuous operation and minimizing downtime.</p>\n</li>\n<li><p><strong>Partition Tolerance</strong>: MongoDB is designed to handle network partitions. During a partition, the system will try to maintain availability and continue operations on the available nodes. However, if a partition occurs and a majority of nodes cannot be reached, MongoDB may become unavailable for writes until the partition is resolved and a majority quorum is re-established.</p>\n</li>\n</ol>\n<p>Given these features, MongoDB generally aligns with the <strong>AP (Availability and Partition Tolerance)</strong> aspect of the CAP theorem. It provides high availability and can handle network partitions, but it may sacrifice some consistency during partitions. So If <strong>Network partition</strong> happened so one node can't communicate with other but i still need the latest data, As we configured as AP system so it will give me the latest data from that node even all the node is not synchronized and this data you get from the server might be rolled back. Hence sacrificing the <strong>Consistency</strong>. Yeah !! I said it before.!!!</p>\n<h2 id=\"heading-but-can-i-change-it\">But Can I Change it??!!</h2>\n<p>Yes!!!! you can . In order to do that you need to write the read and write concern. If you want to know about them here is my another blog link</p>\n<p><a target=\"_blank\" href=\"https://codewithtanvir.hashnode.dev/database-transaction\">Read Concern</a></p>\n<h4 id=\"heading-optimizing-for-consistency-and-partition-tolerance\"><strong>Optimizing for Consistency and Partition Tolerance</strong></h4>\n<pre><code class=\"lang-json\"><span class=\"hljs-comment\">// Connect to MongoDB shell</span>\nuse yourDatabaseName;\n\n<span class=\"hljs-comment\">// Insert a document with write concern \"majority\"</span>\ndb.yourCollectionName.insertOne(\n  { key: <span class=\"hljs-string\">\"value\"</span> },\n  { writeConcern: { w: <span class=\"hljs-string\">\"majority\"</span> } }\n);\n\n<span class=\"hljs-comment\">// Find the document with read concern \"majority\"</span>\nconst result = db.yourCollectionName.findOne(\n  { key: <span class=\"hljs-string\">\"value\"</span> },\n  { readConcern: { level: <span class=\"hljs-string\">\"majority\"</span> } }\n);\n\nprintjson(result);\n</code></pre>\n<ul>\n<li><p><strong>Consistency</strong>: Data is written and read from the majority of nodes.</p>\n</li>\n<li><p><strong>Partition Tolerance</strong>: During partitions, operations may be delayed or unavailable if the majority of nodes cannot be reached.</p>\n</li>\n</ul>\n<h4 id=\"heading-2-optimizing-for-availability-and-partition-tolerance\">2. <strong>Optimizing for Availability and Partition Tolerance</strong></h4>\n<pre><code class=\"lang-json\">use yourDatabaseName;\n\n<span class=\"hljs-comment\">// Insert a document with write concern of 1 (acknowledged by the primary)</span>\ndb.yourCollectionName.insertOne(\n  { key: <span class=\"hljs-string\">\"value\"</span> },\n  { writeConcern: { w: <span class=\"hljs-number\">1</span> } }\n);\n\n<span class=\"hljs-comment\">// Find the document with read concern \"local\"</span>\nconst result = db.yourCollectionName.findOne(\n  { key: <span class=\"hljs-string\">\"value\"</span> },\n  { readConcern: { level: <span class=\"hljs-string\">\"local\"</span> } }\n);\n\nprintjson(result);\n</code></pre>\n<ul>\n<li><p><strong>Availability</strong>: Writes and reads are acknowledged quickly, even if not all nodes are up-to-date.</p>\n</li>\n<li><p><strong>Partition Tolerance</strong>: The system remains operational and responsive, but data might be inconsistent during network partitions.</p>\n</li>\n</ul>\n<p>In MongoDB, achieving <strong>CA</strong> typically isn't feasible in a distributed setup due to the inherent nature of distributed systems and the need to handle network partitions. Network failures are a part of the operational environment in which distributed databases function. They are not caused by the database itself but are inherent to the complexities of distributed systems and network communication.</p>\n","contentMarkdown":"In the world of distributed databases, the CAP theorem, also known as Brewer's theorem, provides a foundational framework for understanding the trade-offs between different system characteristics. Before diving into CAP Theorem we need some knowledge about distributed system. Let's talk about that first.\n\n### What is Distributed System?\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1724304518545/3b573207-5138-4c2e-9d35-1e5ae3d40260.jpeg align=\"center\")\n\nA distributed system is a collection of independent computers that appear to the users of the system as a single coherent system. These systems are designed to share resources and coordinate their actions by passing messages. Distributed systems are ubiquitous in modern computing, powering everything from large-scale web applications to cloud services and IoT networks.\n\n### **Key Characteristics of Distributed Systems**\n\n1. **Scalability**: Distributed systems are designed to handle increasing loads by adding more resources (e.g., servers, storage) to the system. This can be achieved through horizontal scaling (adding more machines) or vertical scaling (upgrading existing machines).\n    \n2. **Fault Tolerance**: Distributed systems are designed to continue functioning even if some components fail. This is achieved through redundancy, replication, and failover mechanisms.\n    \n3. **Concurrency**: Distributed systems often need to handle multiple tasks simultaneously. Concurrency control mechanisms ensure that these tasks do not interfere with each other, maintaining data consistency and integrity.\n    \n4. **Transparency**: Users and applications should interact with the distributed system as if it were a single, coherent system. This transparency hides the complexity of the underlying distributed architecture.\n    \n5. **Heterogeneity**: Distributed systems often consist of diverse hardware and software components. The system must be able to integrate and manage these heterogeneous elements seamlessly.\n    \n\n### **Challenges in Distributed Systems**\n\n1. **Network Latency**: Communication between nodes in a distributed system can introduce delays, which can affect performance and consistency.\n    \n2. **Partial Failures**: Unlike centralized systems, distributed systems can experience partial failures where some components fail while others continue to operate. Handling these failures gracefully is a significant challenge.\n    \n3. **Consistency**: Ensuring that all nodes in a distributed system have a consistent view of the data is complex, especially in the presence of network partitions and failures.\n    \n4. **Security**: Distributed systems are often more vulnerable to security threats due to their distributed nature. Ensuring secure communication and data integrity is crucial.\n    \n5. **Coordination**: Coordinating the actions of multiple nodes to achieve a common goal can be complex and requires sophisticated algorithms and protocols.\n    \n\nDatabases like **MongoDB**, Cassandra, and CockroachDB are designed to handle distributed data storage and retrieval, providing scalability and fault tolerance.\n\n### What is the CAP Theorem?\n\n> In distributed systems, you can only have two out of Consistency, Availability, and Partition Tolerance. You have to choose which two matter most to you\n\n### What is Consistency , Availability & Partition Tolerance??!!\n\n* **Consistency**: Ensuring that every read returns the most recent write means that the system must synchronize and agree on the latest state of the data across all nodes. This requires coordination and communication between nodes to ensure that all updates are seen by all nodes.\n    \n* **Availability**: To be available, a system must respond to every request, even if it cannot guarantee that the data returned is the most recent. This means that the system continues to serve requests without interruption, which often involves accepting reads and writes even when there might be discrepancies between nodes.\n    \n* **Partition Tolerance**: A distributed system is subject to network failures or partitions, where some nodes cannot communicate with others. Partition tolerance means the system must continue operating even when parts of it are isolated. However, maintaining this while also ensuring consistency and availability poses significant challenges.\n    \n\n### Why Only Two? What's the problem with Three??!!\n\nHere’s why achieving all three properties simultaneously is typically infeasible:\n\n1. **Consistency and Partition Tolerance (CP)**\n    \n    * When focusing on **Consistency** and **Partition Tolerance**, the system must ensure that all nodes have the same data despite network partitions. This often means that if a partition occurs, the system might sacrifice **Availability**. For example, during a network partition, if nodes cannot communicate to agree on the latest state of the data, the system may reject requests (both reads and writes) to avoid serving outdated or inconsistent data.\n        \n    * **Long Story Short** : **Network partition** happened so one node can't communicate with other but i still need the latest data, but server doesn't have right now. so it will reject the request hence sacrificing the **Availability**.\n        \n2. **Availability and Partition Tolerance (AP)**\n    \n    * For **Availability** and **Partition Tolerance**, the system must continue to operate and serve requests even if some nodes are isolated. This might lead to temporary inconsistencies if nodes are operating independently of each other. To maintain availability, the system might serve stale or conflicting data because it cannot wait to ensure all nodes have synchronized before responding to requests.\n        \n    * **Long Story Short** : **Network partition** happened so one node can't communicate with other but i still need the latest data, As we configured as AP system so it will give me the latest data from that node even all the node is not synchronized and this data you get from the server might be rolled back. Hence sacrificing the **Consistency**.\n        \n3. **Consistency and Availability (CA)**\n    \n    * To ensure **Consistency** and **Availability**, the system must respond to every request with the most recent data. However, this is typically not feasible in the presence of network partitions. To achieve consistency and availability, the system needs to coordinate all nodes, but network partitions can prevent nodes from communicating, making it impossible to maintain both properties simultaneously.\n        \n    * **Long Story Short** : If you want consistent data and available at the same time in all nodes. you have to make sure that the do not stop communicating with each other. Because if network partition occurs then your nodes can't be consistent or available. So you need consistency and availability sacrifice the chance of partition \\[*in real life it is not practical by the way.*\\]\n        \n    \n    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1724306663598/dd43e476-d26f-4576-9c91-3f3486896bf0.jpeg align=\"center\")\n    \n\n## MongoDB and the CAP Theorem\n\nMongoDB is a popular NoSQL database designed for high performance and flexibility. To understand how MongoDB aligns with the CAP theorem, let's explore how it balances consistency, availability, and partition tolerance:\n\n1. **Consistency**: MongoDB offers strong consistency by default. In a replica set, writes are acknowledged only after they are written to the primary and replicated to the majority of the secondary nodes. This ensures that all reads will see the most recent write once the write is acknowledged.\n    \n2. **Availability**: MongoDB aims for high availability by using replica sets. If the primary node fails, one of the secondary nodes is automatically promoted to primary, ensuring continuous operation and minimizing downtime.\n    \n3. **Partition Tolerance**: MongoDB is designed to handle network partitions. During a partition, the system will try to maintain availability and continue operations on the available nodes. However, if a partition occurs and a majority of nodes cannot be reached, MongoDB may become unavailable for writes until the partition is resolved and a majority quorum is re-established.\n    \n\nGiven these features, MongoDB generally aligns with the **AP (Availability and Partition Tolerance)** aspect of the CAP theorem. It provides high availability and can handle network partitions, but it may sacrifice some consistency during partitions. So If **Network partition** happened so one node can't communicate with other but i still need the latest data, As we configured as AP system so it will give me the latest data from that node even all the node is not synchronized and this data you get from the server might be rolled back. Hence sacrificing the **Consistency**. Yeah !! I said it before.!!!\n\n## But Can I Change it??!!\n\nYes!!!! you can . In order to do that you need to write the read and write concern. If you want to know about them here is my another blog link\n\n[Read Concern](https://codewithtanvir.hashnode.dev/database-transaction)\n\n#### **Optimizing for Consistency and Partition Tolerance**\n\n```json\n// Connect to MongoDB shell\nuse yourDatabaseName;\n\n// Insert a document with write concern \"majority\"\ndb.yourCollectionName.insertOne(\n  { key: \"value\" },\n  { writeConcern: { w: \"majority\" } }\n);\n\n// Find the document with read concern \"majority\"\nconst result = db.yourCollectionName.findOne(\n  { key: \"value\" },\n  { readConcern: { level: \"majority\" } }\n);\n\nprintjson(result);\n```\n\n* **Consistency**: Data is written and read from the majority of nodes.\n    \n* **Partition Tolerance**: During partitions, operations may be delayed or unavailable if the majority of nodes cannot be reached.\n    \n\n#### 2\\. **Optimizing for Availability and Partition Tolerance**\n\n```json\nuse yourDatabaseName;\n\n// Insert a document with write concern of 1 (acknowledged by the primary)\ndb.yourCollectionName.insertOne(\n  { key: \"value\" },\n  { writeConcern: { w: 1 } }\n);\n\n// Find the document with read concern \"local\"\nconst result = db.yourCollectionName.findOne(\n  { key: \"value\" },\n  { readConcern: { level: \"local\" } }\n);\n\nprintjson(result);\n```\n\n* **Availability**: Writes and reads are acknowledged quickly, even if not all nodes are up-to-date.\n    \n* **Partition Tolerance**: The system remains operational and responsive, but data might be inconsistent during network partitions.\n    \n\nIn MongoDB, achieving **CA** typically isn't feasible in a distributed setup due to the inherent nature of distributed systems and the need to handle network partitions. Network failures are a part of the operational environment in which distributed databases function. They are not caused by the database itself but are inherent to the complexities of distributed systems and network communication.","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1724304213174/0d593d9e-b261-4a95-b976-0fc3fae95b3b.jpeg","brief":"In the world of distributed databases, the CAP theorem, also known as Brewer's theorem, provides a foundational framework for understanding the trade-offs between different system characteristics. Before diving into CAP Theorem we need some knowledge...","author":"658438ff6397b8f4db0834fe","sB":false,"isRepublished":false,"readTime":7,"draft":"66c6c97de0c26eb9a09ee625","tags":["64c9666dbd98e68ce26bcef4","57d013c13f4d8e2a1947a248","56744722958ef13879b94f6f","56744722958ef13879b950eb","5c607d20b8a4a3ad13247bf2"],"publication":"6584392d6ae26d33cf572bb6","ogImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1724308114837/bd5ef0a6-a1d0-4458-8f29-ed92a7217bab.jpeg","metaTitle":"Understanding the CAP Theorem with MongoDB: Balancing Consistency, Ava","metaDescription":"Learn how MongoDB handles the CAP theorem in distributed systems. Balance consistency, availability, and partition tolerance effectively.","isNewsletterActivated":true,"coAuthors":[],"pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"66c6db287be0bfa794361b0c"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"_id":"66c5c67e9daf697a6c8de986","createdAt":"2024-08-21T10:50:38.538Z","updatedAt":"2024-08-21T10:50:38.538Z","views":14,"isActive":true,"hasLatex":false,"popularity":7005.0275,"discussionScore":0,"enableToc":true,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"disableComments":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"slugOverridden":true,"tweetOptions":{"enabled":false},"title":"How Transactions Work in Relational vs. Document Databases","cuid":"cm03qgabt001o09l92i8j72gb","dateAdded":"2024-08-21T10:50:38.537Z","isCoverAttributionHidden":false,"coverImageAttribution":"","coverImagePhotographer":"","stickCoverToBottom":false,"slug":"database-transaction","toc":[[{"id":"db120f3e-57a4-4dcc-97c3-d4e24b8f0d93","level":3,"previousLevel":null,"parentId":null,"slug":"what-is-a-database-transaction","title":"What is a Database Transaction ??!!!!"}],[{"id":"f91694b2-5574-495f-886c-09f0dc040ea8","level":3,"previousLevel":3,"parentId":null,"slug":"acid-principle","title":"ACID Principle"}],[{"id":"029e6c97-a652-4897-b8d7-5fa1014eacb1","level":3,"previousLevel":3,"parentId":null,"slug":"a-atomicity","title":"A - ATOMICITY"}],[{"id":"4987948e-e5cd-485e-a123-5f689147da8d","level":3,"previousLevel":3,"parentId":null,"slug":"c-consistency","title":"C - CONSISTENCY"}],[{"id":"6aa9d6cd-cb55-4e19-8f8c-65f12ffb6bfe","level":3,"previousLevel":3,"parentId":null,"slug":"i-isolation","title":"I - ISOLATION"}],[{"id":"f88c6b9a-6481-4bdd-91a4-7eaf225a9d95","level":3,"previousLevel":3,"parentId":null,"slug":"d-durability","title":"D - DURABILITY"}],[{"id":"c0a93db2-e957-4ce9-88a3-ae93649c93fc","level":2,"previousLevel":3,"parentId":null,"slug":"lets-see-a-real-life-example","title":"Let's See a Real Life Example"}],[{"id":"07820f24-1db4-40e5-a5c1-b37ca4508355","level":3,"previousLevel":2,"parentId":"c0a93db2-e957-4ce9-88a3-ae93649c93fc","slug":"scenario-details","title":"Scenario Details"}],[{"id":"beb280d9-9043-4764-bbdf-1b6ab4c0bb2a","level":4,"previousLevel":3,"parentId":"07820f24-1db4-40e5-a5c1-b37ca4508355","slug":"1-customer-purchase","title":"1. Customer Purchase"}],[{"id":"205474a4-dbad-40cb-84af-1494439d1573","level":3,"previousLevel":4,"parentId":"c0a93db2-e957-4ce9-88a3-ae93649c93fc","slug":"transaction-flow","title":"Transaction Flow"}],[{"id":"bef6cd07-cc26-4bd6-9e60-42ce05949c0a","level":2,"previousLevel":3,"parentId":null,"slug":"coding-example-for-relational-database-system","title":"Coding Example For Relational Database system"}],[{"id":"cad20cb6-849c-490d-bb7a-a7ca97e1bbef","level":2,"previousLevel":2,"parentId":null,"slug":"for-non-relational-database-system-mongodb","title":"For Non Relational Database system (MongoDB)"}],[{"id":"3dde6e89-4b43-4e96-b46d-0f9bdf4951df","level":3,"previousLevel":2,"parentId":"cad20cb6-849c-490d-bb7a-a7ca97e1bbef","slug":"what-is-read-concern-in-mongodb","title":"What is Read Concern in MongoDB?"}],[{"id":"d2f18931-45b6-4369-becc-f9e1e43fe6ed","level":3,"previousLevel":3,"parentId":"cad20cb6-849c-490d-bb7a-a7ca97e1bbef","slug":"available-for-transactions-snapshot-read-concern-ensures-that-you-read-data-that-is-consistent-with-the-start-of-a-transaction","title":"Available for transactions, \"snapshot\" read concern ensures that you read data that is consistent with the start of a transaction."}],[{"id":"9af9485a-6a6b-46ca-9270-1db7874face4","level":3,"previousLevel":3,"parentId":"cad20cb6-849c-490d-bb7a-a7ca97e1bbef","slug":"scenario","title":"Scenario:"}],[{"id":"f3b8683e-3617-48df-8edd-c3f4587bef27","level":2,"previousLevel":3,"parentId":null,"slug":"coding-example-using-mongodb","title":"Coding Example Using MongoDB"}],[{"id":"bc02737f-f91f-4a7b-a672-7d630402afbe","level":3,"previousLevel":2,"parentId":"f3b8683e-3617-48df-8edd-c3f4587bef27","slug":"lets-explain-it-one-by-one","title":"Let's Explain it One By One"}],[{"id":"8a3ee084-e1db-4d65-88d5-773ac2f60a40","level":3,"previousLevel":3,"parentId":"f3b8683e-3617-48df-8edd-c3f4587bef27","slug":"key-points","title":"Key Points"}],[{"id":"0cdc3363-5216-41d5-9341-2b54c9fdae17","level":2,"previousLevel":3,"parentId":null,"slug":"side-by-side-comparison","title":"Side By Side Comparison"}]],"content":"<h3 id=\"heading-what-is-a-database-transaction\">What is a Database Transaction ??!!!!</h3>\n<p>A <strong>database transaction</strong> is a sequence of operations performed as a single logical unit of work. These operations can include creating, reading, updating, or deleting data in a database. The key feature of a transaction is that it ensures the integrity and consistency of the database, even in the face of errors, system failures, or concurrent access by multiple users. It is closely related with database ACID principle. So lets go to the ACID principle.</p>\n<h3 id=\"heading-acid-principle\">ACID Principle</h3>\n<p>The concept of a transaction is closely associated with the <strong>ACID</strong> properties, which are fundamental principles that ensure reliable processing in a database. ACID stands for</p>\n<h3 id=\"heading-a-atomicity\">A - ATOMICITY</h3>\n<ul>\n<li><p>Atomicity ensures that a transaction is treated as a single, indivisible unit of work. This means that either all the operations in the transaction are completed successfully, or none of them are applied.</p>\n</li>\n<li><p>Imagine you are running an inventory system where you need to update the quantity of a product and record a sale. The transaction involves these steps:</p>\n<ol>\n<li><p><strong>Check if the product has enough quantity (e.g., 2 units available).</strong></p>\n</li>\n<li><p><strong>If yes, decrement the product quantity by 2.</strong></p>\n</li>\n<li><p><strong>Insert a record in the Sales</strong> collection to note the sale of 2 units.</p>\n</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"heading-c-consistency\">C - CONSISTENCY</h3>\n<ul>\n<li><p>Consistency ensures that a transaction brings the database from one valid state to another, maintaining the integrity of the database according to all defined rules (e.g., constraints, triggers).</p>\n</li>\n<li><p>Before the transaction, the product quantity might be 50, and there are no new sales records. After a successful transaction, the product quantity will be 48, and there will be a new sale record. Consistency ensures that the product quantity is correctly updated and that the sale is recorded according to the business rules (e.g., ensuring that the product quantity never drops below zero).</p>\n</li>\n</ul>\n<h3 id=\"heading-i-isolation\">I - ISOLATION</h3>\n<ul>\n<li><p>Isolation ensures that the operations of one transaction are invisible to other concurrent transactions until the transaction is committed. This prevents interference and ensures that transactions do not affect each other.</p>\n</li>\n<li><p>If another transaction is trying to update the same product's quantity or record another sale at the same time, Isolation guarantees that these transactions won’t interfere with each other. For example, while the first transaction is running, another transaction won’t see the decremented quantity or the new sale record until the first transaction is fully committed.</p>\n</li>\n</ul>\n<h3 id=\"heading-d-durability\">D - DURABILITY</h3>\n<ul>\n<li><p><strong>Definition</strong>: Durability guarantees that once a transaction has been committed, its changes are permanent and will survive system failures. This is typically ensured through mechanisms like logging or writing to non-volatile storage.</p>\n</li>\n<li><p>After the transaction is committed, the product quantity is reduced by 2, and the sale record is added. Durability ensures that even if the system crashes immediately after the transaction, when the system recovers, the product quantity will still be 48, and the sale record will still be present in the database.</p>\n</li>\n</ul>\n<h2 id=\"heading-lets-see-a-real-life-example\">Let's See a Real Life Example</h2>\n<p>You manage an inventory system for an electronics store. The system needs to handle product sales while ensuring that the inventory is accurately updated and sales are properly recorded. The database has two key collections (or tables):</p>\n<ul>\n<li><p><strong>Products</strong>: Stores details about each product, including its available quantity.</p>\n</li>\n<li><p><strong>Sales</strong>: Records details of each sale, including the product sold, quantity sold, and the sale date.</p>\n</li>\n</ul>\n<h3 id=\"heading-scenario-details\">Scenario Details</h3>\n<h4 id=\"heading-1-customer-purchase\">1. <strong>Customer Purchase</strong></h4>\n<p>A customer wants to buy 2 units of a laptop with <code>Product ID: 1</code>. The system needs to:</p>\n<ol>\n<li><p>Check if there are at least 2 units available.</p>\n</li>\n<li><p>If there are, reduce the quantity of the product in the inventory by 2.</p>\n</li>\n<li><p>Record the sale in the <code>Sales</code> collection/table.</p>\n</li>\n</ol>\n<h3 id=\"heading-transaction-flow\">Transaction Flow</h3>\n<ol>\n<li><p><strong>Start Transaction</strong>:</p>\n<ul>\n<li>The system begins a transaction to manage the sale.</li>\n</ul>\n</li>\n<li><p><strong>Check Product Quantity</strong>:</p>\n<ul>\n<li>The system verifies that there are 2 units available.</li>\n</ul>\n</li>\n<li><p><strong>Update Inventory</strong>:</p>\n<ul>\n<li>The product quantity is reduced by 2.</li>\n</ul>\n</li>\n<li><p><strong>Record Sale</strong>:</p>\n<ul>\n<li>The sale of 2 units is recorded in the <code>Sales</code> collection.</li>\n</ul>\n</li>\n<li><p><strong>Commit Transaction</strong>:</p>\n<ul>\n<li>The transaction is successfully completed and committed.</li>\n</ul>\n</li>\n<li><p><strong>Handle System Crash (if any)</strong>:</p>\n<ul>\n<li>If a system crash occurs after committing the transaction, the changes (reduced quantity and recorded sale) are permanent and will persist.</li>\n</ul>\n</li>\n</ol>\n<p>This scenario shows how the ACID properties ensure that the product sale is handled reliably, even in the face of potential errors or concurrent operations.</p>\n<h2 id=\"heading-coding-example-for-relational-database-system\">Coding Example For Relational Database system</h2>\n<p>Suppose you are developing your application based on that scenario. You are using</p>\n<ul>\n<li><p>C# programming language</p>\n</li>\n<li><p>.NET Core Framework</p>\n</li>\n<li><p>MS SQL Server Relational Database for Data Storage</p>\n</li>\n<li><p>Entity Framework Core As <strong>ORM</strong></p>\n</li>\n</ul>\n<p>This is how you make a database Transaction</p>\n<pre><code class=\"lang-csharp\"><span class=\"hljs-keyword\">using</span> (<span class=\"hljs-keyword\">var</span> context = <span class=\"hljs-keyword\">new</span> InventoryContext())\n{\n    <span class=\"hljs-comment\">// transaction start</span>\n    <span class=\"hljs-keyword\">using</span> (<span class=\"hljs-keyword\">var</span> transaction = context.Database.BeginTransaction())\n    {\n        <span class=\"hljs-keyword\">try</span>\n        {\n            <span class=\"hljs-comment\">// Retrieve the product from the database</span>\n            <span class=\"hljs-keyword\">var</span> product = context.Products.SingleOrDefault(p =&gt; p.Id == <span class=\"hljs-number\">1</span>);\n\n            <span class=\"hljs-comment\">// Check if there is enough quantity</span>\n            <span class=\"hljs-comment\">// if product is null it will be immidiately roll back</span>\n            <span class=\"hljs-keyword\">if</span> (product != <span class=\"hljs-literal\">null</span> &amp;&amp; product.Quantity &gt;= <span class=\"hljs-number\">2</span>)\n            {\n                <span class=\"hljs-comment\">// Update the product quantity</span>\n                <span class=\"hljs-comment\">// in this case reduce the quantity by 2</span>\n                product.Quantity -= <span class=\"hljs-number\">2</span>;\n                context.SaveChanges();\n\n                <span class=\"hljs-comment\">// Record the sale</span>\n                <span class=\"hljs-comment\">// adding the information to the sales table</span>\n                <span class=\"hljs-keyword\">var</span> sale = <span class=\"hljs-keyword\">new</span> Sale\n                {\n                    ProductId = <span class=\"hljs-number\">1</span>,\n                    QuantitySold = <span class=\"hljs-number\">2</span>,\n                    Date = DateTime.Now\n                };\n                context.Sales.Add(sale);\n                context.SaveChanges();\n\n                <span class=\"hljs-comment\">// Commit the transaction</span>\n                <span class=\"hljs-comment\">// everything is done so commit </span>\n                <span class=\"hljs-comment\">// and make permanent change in the database</span>\n                transaction.Commit();\n            }\n            <span class=\"hljs-keyword\">else</span>\n            {\n                <span class=\"hljs-comment\">// Not enough quantity, roll back the transaction</span>\n                Console.WriteLine(<span class=\"hljs-string\">\"Not enough quantity to complete the sale.\"</span>);\n                transaction.Rollback();\n            }\n        }\n        <span class=\"hljs-keyword\">catch</span> (Exception ex)\n        {\n            <span class=\"hljs-comment\">// If there's an error, roll back the transaction</span>\n            transaction.Rollback();\n            Console.WriteLine(<span class=\"hljs-string\">\"Transaction failed: \"</span> + ex.Message);\n        }\n    }\n}\n</code></pre>\n<blockquote>\n<p>Remember in the transaction wither everything recorded perfectly or nothing will be recorded. NO IN BETWEEN.</p>\n</blockquote>\n<h2 id=\"heading-for-non-relational-database-system-mongodb\">For Non Relational Database system (MongoDB)</h2>\n<p>Before i give the example of this in a non relational database you need to know one term which is \"<strong><em>Read Concern\"</em></strong></p>\n<h3 id=\"heading-what-is-read-concern-in-mongodb\">What is <strong>Read Concern</strong> in MongoDB?</h3>\n<p>Read Concern in MongoDB defines the level of isolation for read operations, meaning it controls the consistency and durability of the data you read from your database. It determines how \"fresh\" the data is that you're reading.</p>\n<p><strong>Read Concern Levels:</strong></p>\n<p>MongoDB supports different levels of Read Concern:</p>\n<ol>\n<li><p><strong>\"local\" (Default):</strong></p>\n<ul>\n<li>The query returns the most recent data available on the node that receives the read operation. This level doesn't guarantee that the data has been replicated to other nodes in a replica set. It's fast but may return stale data if other nodes are not yet synchronized.</li>\n</ul>\n</li>\n<li><p><strong>\"available\":</strong></p>\n<ul>\n<li>Similar to \"local\", but ensures that the query reads data even if a replica set member is recovering.</li>\n</ul>\n</li>\n<li><p><strong>\"majority\":</strong></p>\n<ul>\n<li>The query returns data that has been acknowledged by a majority of the replica set members. This provides stronger consistency, ensuring that the data you read is the same across the majority of nodes, but it may be slower due to the need for confirmation from multiple nodes.</li>\n</ul>\n</li>\n<li><p><strong>\"linearizable\":</strong></p>\n<ul>\n<li>The query returns data that reflects all successful writes issued with a \"majority\" write concern before the read operation. It provides the strongest consistency, ensuring that you always read the most recent data, but it can be much slower and impact performance.</li>\n</ul>\n</li>\n<li><p><strong><em>\"snapshot\":</em></strong></p>\n<ul>\n<li><h3 id=\"heading-available-for-transactions-snapshot-read-concern-ensures-that-you-read-data-that-is-consistent-with-the-start-of-a-transaction\"><strong><em>Available for transactions, \"snapshot\" read concern ensures that you read data that is consistent with the start of a transaction.</em></strong></h3>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"heading-scenario\">Scenario:</h3>\n<p>Imagine you're managing a small inventory system with a MongoDB database. You have two collections:</p>\n<ol>\n<li><p><code>products</code> <strong>- storing product details.</strong></p>\n</li>\n<li><p><code>sales</code> <strong>- recording sales transactions.</strong></p>\n</li>\n</ol>\n<p>You want to ensure that when you read data from these collections during a transaction, the data is consistent and reflects a specific point in time, even if other operations are happening concurrently.</p>\n<pre><code class=\"lang-json\"><span class=\"hljs-comment\">// products collection</span>\n{\n    <span class=\"hljs-attr\">\"_id\"</span>: <span class=\"hljs-number\">1</span>,\n    <span class=\"hljs-attr\">\"name\"</span>: <span class=\"hljs-string\">\"Laptop\"</span>,\n    <span class=\"hljs-attr\">\"quantity\"</span>: <span class=\"hljs-number\">50</span>,\n    <span class=\"hljs-attr\">\"price\"</span>: <span class=\"hljs-number\">1000</span>\n}\n\n<span class=\"hljs-comment\">// sales collection</span>\n{\n    <span class=\"hljs-attr\">\"_id\"</span>: <span class=\"hljs-number\">1</span>,\n    <span class=\"hljs-attr\">\"product_id\"</span>: <span class=\"hljs-number\">1</span>,\n    <span class=\"hljs-attr\">\"quantity_sold\"</span>: <span class=\"hljs-number\">2</span>,\n    <span class=\"hljs-attr\">\"date\"</span>: <span class=\"hljs-string\">\"2024-08-21\"</span>\n}\n</code></pre>\n<h2 id=\"heading-coding-example-using-mongodb\">Coding Example Using MongoDB</h2>\n<p>Here is the code for making transaction using \"<strong>Snapshot</strong>\" Read Concern.</p>\n<pre><code class=\"lang-javascript\"><span class=\"hljs-keyword\">const</span> session = db.getMongo().startSession();\nsession.startTransaction({\n    <span class=\"hljs-attr\">readConcern</span>: { <span class=\"hljs-attr\">level</span>: <span class=\"hljs-string\">\"snapshot\"</span> }\n});\n\n<span class=\"hljs-keyword\">try</span> {\n    <span class=\"hljs-keyword\">const</span> product = session.getDatabase(<span class=\"hljs-string\">\"inventory\"</span>).products.findOne({ <span class=\"hljs-attr\">_id</span>: <span class=\"hljs-number\">1</span> });\n\n    <span class=\"hljs-keyword\">if</span> (product.quantity &gt;= <span class=\"hljs-number\">2</span>) {\n        <span class=\"hljs-comment\">// Update the product quantity</span>\n        session.getDatabase(<span class=\"hljs-string\">\"inventory\"</span>).products.updateOne(\n            { <span class=\"hljs-attr\">_id</span>: <span class=\"hljs-number\">1</span> },\n            { <span class=\"hljs-attr\">$inc</span>: { <span class=\"hljs-attr\">quantity</span>: <span class=\"hljs-number\">-2</span> } }\n        );\n\n        <span class=\"hljs-comment\">// Record the sale</span>\n        session.getDatabase(<span class=\"hljs-string\">\"inventory\"</span>).sales.insertOne({\n            <span class=\"hljs-attr\">product_id</span>: <span class=\"hljs-number\">1</span>,\n            <span class=\"hljs-attr\">quantity_sold</span>: <span class=\"hljs-number\">2</span>,\n            <span class=\"hljs-attr\">date</span>: <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Date</span>()\n        });\n\n        <span class=\"hljs-comment\">// Commit the transaction</span>\n        session.commitTransaction();\n    } <span class=\"hljs-keyword\">else</span> {\n        <span class=\"hljs-comment\">// Abort the transaction if there's not enough quantity</span>\n        session.abortTransaction();\n        <span class=\"hljs-built_in\">console</span>.log(<span class=\"hljs-string\">\"Not enough quantity to complete the sale.\"</span>);\n    }\n} <span class=\"hljs-keyword\">catch</span> (error) {\n    <span class=\"hljs-comment\">// If an error occurs, abort the transaction</span>\n    session.abortTransaction();\n    <span class=\"hljs-built_in\">console</span>.error(<span class=\"hljs-string\">\"Transaction failed: \"</span>, error);\n} <span class=\"hljs-keyword\">finally</span> {\n    session.endSession();\n}\n</code></pre>\n<h3 id=\"heading-lets-explain-it-one-by-one\">Let's Explain it One By One</h3>\n<ul>\n<li>This line bellow starts a new session in MongoDB. A session is necessary for running a transaction because it provides a context in which the transaction occurs. The session allows MongoDB to track the operations within the transaction and ensure they are applied atomically (all or nothing).</li>\n</ul>\n<pre><code class=\"lang-javascript\"><span class=\"hljs-keyword\">const</span> session = db.getMongo().startSession();\n</code></pre>\n<ul>\n<li>We start the transaction within the session. The <code>startTransaction()</code> method begins the transaction, and we specify the <code>readConcern</code> level as <code>\"snapshot\"</code>. This ensures that all reads during the transaction will see a consistent view of the data as it was at the start of the transaction, regardless of any other operations occurring concurrently.</li>\n</ul>\n<pre><code class=\"lang-javascript\">session.startTransaction({\n    <span class=\"hljs-attr\">readConcern</span>: { <span class=\"hljs-attr\">level</span>: <span class=\"hljs-string\">\"snapshot\"</span> }\n});\n</code></pre>\n<ul>\n<li>We use a <code>try</code> block to handle any errors that might occur during the transaction. In this line, we're reading a document from the <code>products</code> collection where <code>_id</code> equals <code>1</code>. The <code>findOne()</code> method retrieves a single document, and since this read operation is part of the transaction, it uses the <code>\"snapshot\"</code> read concern to ensure that the data is consistent with the start of the transaction.</li>\n</ul>\n<pre><code class=\"lang-javascript\"><span class=\"hljs-keyword\">try</span> {\n    <span class=\"hljs-keyword\">const</span> product = session.getDatabase(<span class=\"hljs-string\">\"inventory\"</span>).products.findOne({ <span class=\"hljs-attr\">_id</span>: <span class=\"hljs-number\">1</span> });\n</code></pre>\n<ul>\n<li>This line checks if the <code>quantity</code> of the product is greater than or equal to <code>2</code>. This is important because we only want to proceed with the sale if there's enough stock available. If the condition is true, the transaction continues; if not, it will be aborted.</li>\n</ul>\n<pre><code class=\"lang-javascript\"><span class=\"hljs-keyword\">if</span> (product.quantity &gt;= <span class=\"hljs-number\">2</span>) {\n</code></pre>\n<ul>\n<li>If the product has enough quantity, we proceed to update the document. The <code>updateOne()</code> method is used to decrement the <code>quantity</code> field by <code>2</code>. The <code>$inc</code> operator decreases the <code>quantity</code> by the specified amount (<code>-2</code> in this case). This operation is part of the transaction, so it won’t be visible outside the transaction until it's committed</li>\n</ul>\n<pre><code class=\"lang-javascript\">session.getDatabase(<span class=\"hljs-string\">\"inventory\"</span>).products.updateOne(\n    { <span class=\"hljs-attr\">_id</span>: <span class=\"hljs-number\">1</span> },\n    { <span class=\"hljs-attr\">$inc</span>: { <span class=\"hljs-attr\">quantity</span>: <span class=\"hljs-number\">-2</span> } }\n);\n</code></pre>\n<ul>\n<li>After updating the product quantity, we record the sale in the <code>sales</code> collection. The <code>insertOne()</code> method adds a new document to the <code>sales</code> collection with details about the sale, such as <code>product_id</code>, <code>quantity_sold</code>, and the current date. This insert operation is also part of the transaction.</li>\n</ul>\n<pre><code class=\"lang-javascript\">session.getDatabase(<span class=\"hljs-string\">\"inventory\"</span>).sales.insertOne({\n    <span class=\"hljs-attr\">product_id</span>: <span class=\"hljs-number\">1</span>,\n    <span class=\"hljs-attr\">quantity_sold</span>: <span class=\"hljs-number\">2</span>,\n    <span class=\"hljs-attr\">date</span>: <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">Date</span>()\n});\n</code></pre>\n<ul>\n<li>After updating the product quantity, we record the sale in the <code>sales</code> collection. The <code>insertOne()</code> method adds a new document to the <code>sales</code> collection with details about the sale, such as <code>product_id</code>, <code>quantity_sold</code>, and the current date. This insert operation is also part of the transaction.</li>\n</ul>\n<pre><code class=\"lang-javascript\">session.commitTransaction();\n</code></pre>\n<ul>\n<li>If the initial check (<code>product.quantity &gt;= 2</code>) fails, the transaction is aborted using <code>abortTransaction()</code>. Aborting the transaction means that none of the operations within it will be applied to the database. We also log a message to indicate that the sale couldn't be completed due to insufficient stock.</li>\n</ul>\n<pre><code class=\"lang-javascript\">} <span class=\"hljs-keyword\">else</span> {\n    session.abortTransaction();\n    <span class=\"hljs-built_in\">console</span>.log(<span class=\"hljs-string\">\"Not enough quantity to complete the sale.\"</span>);\n}\n</code></pre>\n<ul>\n<li>If an error is thrown at any point within the <code>try</code> block, the transaction is aborted to ensure that no partial changes are applied to the database. The error message is also logged for debugging purposes</li>\n</ul>\n<pre><code class=\"lang-javascript\">} <span class=\"hljs-keyword\">catch</span> (error) {\n    session.abortTransaction();\n    <span class=\"hljs-built_in\">console</span>.error(<span class=\"hljs-string\">\"Transaction failed: \"</span>, error);\n}\n</code></pre>\n<ul>\n<li>The <code>finally</code> block runs regardless of whether the transaction was successful or not. The <code>endSession()</code> method is called to clean up the session, releasing any resources associated with it. It's a good practice to end the session after the transaction is complete to avoid resource leaks.</li>\n</ul>\n<pre><code class=\"lang-javascript\"><span class=\"hljs-keyword\">finally</span> {\n    session.endSession();\n}\n</code></pre>\n<h3 id=\"heading-key-points\">Key Points</h3>\n<ul>\n<li><p><strong>Session Management:</strong> The code starts and manages a session, which is required for transactions in MongoDB.</p>\n</li>\n<li><p><strong>Transaction:</strong> The transaction ensures that multiple operations (reading the product, updating the quantity, and inserting a sale record) are treated as a single atomic unit.</p>\n</li>\n<li><p><strong>Read Concern</strong> <code>\"snapshot\"</code>: This guarantees that the reads within the transaction see a consistent view of the data, even if other operations are happening concurrently.</p>\n</li>\n<li><p><strong>Error Handling:</strong> The <code>try-catch-finally</code> structure ensures that errors are handled gracefully, with the transaction being aborted if something goes wrong.</p>\n</li>\n</ul>\n<h2 id=\"heading-side-by-side-comparison\">Side By Side Comparison</h2>\n<div class=\"hn-table\">\n<table>\n<thead>\n<tr>\n<td>Concept</td><td>MongoDB</td><td>MSSQL Server With EF Core</td></tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><em>Session/Context</em></strong></td><td><code>startSession()</code> to create a session</td><td><code>InventoryContext</code> as the database context.</td></tr>\n<tr>\n<td><strong><em>Transaction Start</em></strong></td><td><code>startTransaction({ readConcern: { level: \"snapshot\" } })</code></td><td><code>BeginTransaction()</code> to start a transaction.</td></tr>\n<tr>\n<td><strong><em>Read Operation</em></strong></td><td><code>findOne({ _id: 1 })</code></td><td><code>SingleOrDefault(p =&gt;</code> <a target=\"_blank\" href=\"http://p.Id\"><code>p.Id</code></a> <code>== 1)</code> to fetch the product by ID.</td></tr>\n<tr>\n<td><strong><em>Condition Check</em></strong></td><td><code>if (product.quantity &gt;= 2)</code></td><td><code>if (product != null</code> <code>&amp;&amp;</code> <code>product.Quantity &gt;= 2)</code></td></tr>\n<tr>\n<td><strong><em>Update Operation</em></strong></td><td><code>updateOne({ _id: 1 }, { $inc: { quantity: -2 } })</code></td><td><code>product.Quantity -= 2; context.SaveChanges();</code> to decrease the quantity.</td></tr>\n<tr>\n<td><strong><em>Insert Operation</em></strong></td><td><code>insertOne({ product_id: 1, quantity_sold: 2, date: new Date() })</code></td><td><code>context.Sales.Add(sale); context.SaveChanges();</code> to insert a new sale record.</td></tr>\n<tr>\n<td><strong><em>Commit Transaction</em></strong></td><td><code>commitTransaction()</code></td><td><code>transaction.Commit()</code> to commit the transaction.</td></tr>\n<tr>\n<td><strong><em>Rollback on Error</em></strong></td><td><code>abortTransaction()</code></td><td><code>transaction.Rollback()</code> to roll back the transaction.</td></tr>\n<tr>\n<td><strong><em>Cleanup</em></strong></td><td><code>session.endSession()</code></td><td>Transaction and context are disposed of using <code>using</code> blocks.</td></tr>\n</tbody>\n</table>\n</div>","contentMarkdown":"### What is a Database Transaction ??!!!!\n\nA **database transaction** is a sequence of operations performed as a single logical unit of work. These operations can include creating, reading, updating, or deleting data in a database. The key feature of a transaction is that it ensures the integrity and consistency of the database, even in the face of errors, system failures, or concurrent access by multiple users. It is closely related with database ACID principle. So lets go to the ACID principle.\n\n### ACID Principle\n\nThe concept of a transaction is closely associated with the **ACID** properties, which are fundamental principles that ensure reliable processing in a database. ACID stands for\n\n### A - ATOMICITY\n\n* Atomicity ensures that a transaction is treated as a single, indivisible unit of work. This means that either all the operations in the transaction are completed successfully, or none of them are applied.\n    \n* Imagine you are running an inventory system where you need to update the quantity of a product and record a sale. The transaction involves these steps:\n    \n    1. **Check if the product has enough quantity (e.g., 2 units available).**\n        \n    2. **If yes, decrement the product quantity by 2.**\n        \n    3. **Insert a record in the Sales** collection to note the sale of 2 units.\n        \n\n### C - CONSISTENCY\n\n* Consistency ensures that a transaction brings the database from one valid state to another, maintaining the integrity of the database according to all defined rules (e.g., constraints, triggers).\n    \n* Before the transaction, the product quantity might be 50, and there are no new sales records. After a successful transaction, the product quantity will be 48, and there will be a new sale record. Consistency ensures that the product quantity is correctly updated and that the sale is recorded according to the business rules (e.g., ensuring that the product quantity never drops below zero).\n    \n\n### I - ISOLATION\n\n* Isolation ensures that the operations of one transaction are invisible to other concurrent transactions until the transaction is committed. This prevents interference and ensures that transactions do not affect each other.\n    \n* If another transaction is trying to update the same product's quantity or record another sale at the same time, Isolation guarantees that these transactions won’t interfere with each other. For example, while the first transaction is running, another transaction won’t see the decremented quantity or the new sale record until the first transaction is fully committed.\n    \n\n### D - DURABILITY\n\n* **Definition**: Durability guarantees that once a transaction has been committed, its changes are permanent and will survive system failures. This is typically ensured through mechanisms like logging or writing to non-volatile storage.\n    \n* After the transaction is committed, the product quantity is reduced by 2, and the sale record is added. Durability ensures that even if the system crashes immediately after the transaction, when the system recovers, the product quantity will still be 48, and the sale record will still be present in the database.\n    \n\n## Let's See a Real Life Example\n\nYou manage an inventory system for an electronics store. The system needs to handle product sales while ensuring that the inventory is accurately updated and sales are properly recorded. The database has two key collections (or tables):\n\n* **Products**: Stores details about each product, including its available quantity.\n    \n* **Sales**: Records details of each sale, including the product sold, quantity sold, and the sale date.\n    \n\n### Scenario Details\n\n#### 1\\. **Customer Purchase**\n\nA customer wants to buy 2 units of a laptop with `Product ID: 1`. The system needs to:\n\n1. Check if there are at least 2 units available.\n    \n2. If there are, reduce the quantity of the product in the inventory by 2.\n    \n3. Record the sale in the `Sales` collection/table.\n    \n\n### Transaction Flow\n\n1. **Start Transaction**:\n    \n    * The system begins a transaction to manage the sale.\n        \n2. **Check Product Quantity**:\n    \n    * The system verifies that there are 2 units available.\n        \n3. **Update Inventory**:\n    \n    * The product quantity is reduced by 2.\n        \n4. **Record Sale**:\n    \n    * The sale of 2 units is recorded in the `Sales` collection.\n        \n5. **Commit Transaction**:\n    \n    * The transaction is successfully completed and committed.\n        \n6. **Handle System Crash (if any)**:\n    \n    * If a system crash occurs after committing the transaction, the changes (reduced quantity and recorded sale) are permanent and will persist.\n        \n\nThis scenario shows how the ACID properties ensure that the product sale is handled reliably, even in the face of potential errors or concurrent operations.\n\n## Coding Example For Relational Database system\n\nSuppose you are developing your application based on that scenario. You are using\n\n* C# programming language\n    \n* .NET Core Framework\n    \n* MS SQL Server Relational Database for Data Storage\n    \n* Entity Framework Core As **ORM**\n    \n\nThis is how you make a database Transaction\n\n```csharp\nusing (var context = new InventoryContext())\n{\n    // transaction start\n    using (var transaction = context.Database.BeginTransaction())\n    {\n        try\n        {\n            // Retrieve the product from the database\n            var product = context.Products.SingleOrDefault(p => p.Id == 1);\n\n            // Check if there is enough quantity\n            // if product is null it will be immidiately roll back\n            if (product != null && product.Quantity >= 2)\n            {\n                // Update the product quantity\n                // in this case reduce the quantity by 2\n                product.Quantity -= 2;\n                context.SaveChanges();\n\n                // Record the sale\n                // adding the information to the sales table\n                var sale = new Sale\n                {\n                    ProductId = 1,\n                    QuantitySold = 2,\n                    Date = DateTime.Now\n                };\n                context.Sales.Add(sale);\n                context.SaveChanges();\n\n                // Commit the transaction\n                // everything is done so commit \n                // and make permanent change in the database\n                transaction.Commit();\n            }\n            else\n            {\n                // Not enough quantity, roll back the transaction\n                Console.WriteLine(\"Not enough quantity to complete the sale.\");\n                transaction.Rollback();\n            }\n        }\n        catch (Exception ex)\n        {\n            // If there's an error, roll back the transaction\n            transaction.Rollback();\n            Console.WriteLine(\"Transaction failed: \" + ex.Message);\n        }\n    }\n}\n```\n\n> Remember in the transaction wither everything recorded perfectly or nothing will be recorded. NO IN BETWEEN.\n\n## For Non Relational Database system (MongoDB)\n\nBefore i give the example of this in a non relational database you need to know one term which is \"***Read Concern\"***\n\n### What is **Read Concern** in MongoDB?\n\nRead Concern in MongoDB defines the level of isolation for read operations, meaning it controls the consistency and durability of the data you read from your database. It determines how \"fresh\" the data is that you're reading.\n\n**Read Concern Levels:**\n\nMongoDB supports different levels of Read Concern:\n\n1. **\"local\" (Default):**\n    \n    * The query returns the most recent data available on the node that receives the read operation. This level doesn't guarantee that the data has been replicated to other nodes in a replica set. It's fast but may return stale data if other nodes are not yet synchronized.\n        \n2. **\"available\":**\n    \n    * Similar to \"local\", but ensures that the query reads data even if a replica set member is recovering.\n        \n3. **\"majority\":**\n    \n    * The query returns data that has been acknowledged by a majority of the replica set members. This provides stronger consistency, ensuring that the data you read is the same across the majority of nodes, but it may be slower due to the need for confirmation from multiple nodes.\n        \n4. **\"linearizable\":**\n    \n    * The query returns data that reflects all successful writes issued with a \"majority\" write concern before the read operation. It provides the strongest consistency, ensuring that you always read the most recent data, but it can be much slower and impact performance.\n        \n5. ***\"snapshot\":***\n    \n    * ### ***Available for transactions, \"snapshot\" read concern ensures that you read data that is consistent with the start of a transaction.***\n        \n\n### Scenario:\n\nImagine you're managing a small inventory system with a MongoDB database. You have two collections:\n\n1. `products` **- storing product details.**\n    \n2. `sales` **- recording sales transactions.**\n    \n\nYou want to ensure that when you read data from these collections during a transaction, the data is consistent and reflects a specific point in time, even if other operations are happening concurrently.\n\n```json\n// products collection\n{\n    \"_id\": 1,\n    \"name\": \"Laptop\",\n    \"quantity\": 50,\n    \"price\": 1000\n}\n\n// sales collection\n{\n    \"_id\": 1,\n    \"product_id\": 1,\n    \"quantity_sold\": 2,\n    \"date\": \"2024-08-21\"\n}\n\n```\n\n## Coding Example Using MongoDB\n\nHere is the code for making transaction using \"**Snapshot**\" Read Concern.\n\n```javascript\nconst session = db.getMongo().startSession();\nsession.startTransaction({\n    readConcern: { level: \"snapshot\" }\n});\n\ntry {\n    const product = session.getDatabase(\"inventory\").products.findOne({ _id: 1 });\n\n    if (product.quantity >= 2) {\n        // Update the product quantity\n        session.getDatabase(\"inventory\").products.updateOne(\n            { _id: 1 },\n            { $inc: { quantity: -2 } }\n        );\n\n        // Record the sale\n        session.getDatabase(\"inventory\").sales.insertOne({\n            product_id: 1,\n            quantity_sold: 2,\n            date: new Date()\n        });\n\n        // Commit the transaction\n        session.commitTransaction();\n    } else {\n        // Abort the transaction if there's not enough quantity\n        session.abortTransaction();\n        console.log(\"Not enough quantity to complete the sale.\");\n    }\n} catch (error) {\n    // If an error occurs, abort the transaction\n    session.abortTransaction();\n    console.error(\"Transaction failed: \", error);\n} finally {\n    session.endSession();\n}\n```\n\n### Let's Explain it One By One\n\n* This line bellow starts a new session in MongoDB. A session is necessary for running a transaction because it provides a context in which the transaction occurs. The session allows MongoDB to track the operations within the transaction and ensure they are applied atomically (all or nothing).\n    \n\n```javascript\nconst session = db.getMongo().startSession();\n```\n\n* We start the transaction within the session. The `startTransaction()` method begins the transaction, and we specify the `readConcern` level as `\"snapshot\"`. This ensures that all reads during the transaction will see a consistent view of the data as it was at the start of the transaction, regardless of any other operations occurring concurrently.\n    \n\n```javascript\nsession.startTransaction({\n    readConcern: { level: \"snapshot\" }\n});\n```\n\n* We use a `try` block to handle any errors that might occur during the transaction. In this line, we're reading a document from the `products` collection where `_id` equals `1`. The `findOne()` method retrieves a single document, and since this read operation is part of the transaction, it uses the `\"snapshot\"` read concern to ensure that the data is consistent with the start of the transaction.\n    \n\n```javascript\ntry {\n    const product = session.getDatabase(\"inventory\").products.findOne({ _id: 1 });\n```\n\n* This line checks if the `quantity` of the product is greater than or equal to `2`. This is important because we only want to proceed with the sale if there's enough stock available. If the condition is true, the transaction continues; if not, it will be aborted.\n    \n\n```javascript\nif (product.quantity >= 2) {\n```\n\n* If the product has enough quantity, we proceed to update the document. The `updateOne()` method is used to decrement the `quantity` field by `2`. The `$inc` operator decreases the `quantity` by the specified amount (`-2` in this case). This operation is part of the transaction, so it won’t be visible outside the transaction until it's committed\n    \n\n```javascript\nsession.getDatabase(\"inventory\").products.updateOne(\n    { _id: 1 },\n    { $inc: { quantity: -2 } }\n);\n```\n\n* After updating the product quantity, we record the sale in the `sales` collection. The `insertOne()` method adds a new document to the `sales` collection with details about the sale, such as `product_id`, `quantity_sold`, and the current date. This insert operation is also part of the transaction.\n    \n\n```javascript\nsession.getDatabase(\"inventory\").sales.insertOne({\n    product_id: 1,\n    quantity_sold: 2,\n    date: new Date()\n});\n```\n\n* After updating the product quantity, we record the sale in the `sales` collection. The `insertOne()` method adds a new document to the `sales` collection with details about the sale, such as `product_id`, `quantity_sold`, and the current date. This insert operation is also part of the transaction.\n    \n\n```javascript\nsession.commitTransaction();\n```\n\n* If the initial check (`product.quantity >= 2`) fails, the transaction is aborted using `abortTransaction()`. Aborting the transaction means that none of the operations within it will be applied to the database. We also log a message to indicate that the sale couldn't be completed due to insufficient stock.\n    \n\n```javascript\n} else {\n    session.abortTransaction();\n    console.log(\"Not enough quantity to complete the sale.\");\n}\n```\n\n* If an error is thrown at any point within the `try` block, the transaction is aborted to ensure that no partial changes are applied to the database. The error message is also logged for debugging purposes\n    \n\n```javascript\n} catch (error) {\n    session.abortTransaction();\n    console.error(\"Transaction failed: \", error);\n}\n```\n\n* The `finally` block runs regardless of whether the transaction was successful or not. The `endSession()` method is called to clean up the session, releasing any resources associated with it. It's a good practice to end the session after the transaction is complete to avoid resource leaks.\n    \n\n```javascript\nfinally {\n    session.endSession();\n}\n```\n\n### Key Points\n\n* **Session Management:** The code starts and manages a session, which is required for transactions in MongoDB.\n    \n* **Transaction:** The transaction ensures that multiple operations (reading the product, updating the quantity, and inserting a sale record) are treated as a single atomic unit.\n    \n* **Read Concern** `\"snapshot\"`: This guarantees that the reads within the transaction see a consistent view of the data, even if other operations are happening concurrently.\n    \n* **Error Handling:** The `try-catch-finally` structure ensures that errors are handled gracefully, with the transaction being aborted if something goes wrong.\n    \n\n## Side By Side Comparison\n\n| Concept | MongoDB | MSSQL Server With EF Core |\n| --- | --- | --- |\n| ***Session/Context*** | `startSession()` to create a session | `InventoryContext` as the database context. |\n| ***Transaction Start*** | `startTransaction({ readConcern: { level: \"snapshot\" } })` | `BeginTransaction()` to start a transaction. |\n| ***Read Operation*** | `findOne({ _id: 1 })` | `SingleOrDefault(p =>` [`p.Id`](http://p.Id) `== 1)` to fetch the product by ID. |\n| ***Condition Check*** | `if (product.quantity >= 2)` | `if (product != null` `&&` `product.Quantity >= 2)` |\n| ***Update Operation*** | `updateOne({ _id: 1 }, { $inc: { quantity: -2 } })` | `product.Quantity -= 2; context.SaveChanges();` to decrease the quantity. |\n| ***Insert Operation*** | `insertOne({ product_id: 1, quantity_sold: 2, date: new Date() })` | `context.Sales.Add(sale); context.SaveChanges();` to insert a new sale record. |\n| ***Commit Transaction*** | `commitTransaction()` | `transaction.Commit()` to commit the transaction. |\n| ***Rollback on Error*** | `abortTransaction()` | `transaction.Rollback()` to roll back the transaction. |\n| ***Cleanup*** | `session.endSession()` | Transaction and context are disposed of using `using` blocks. |","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1724237159014/4e5b629d-b806-427e-ac4d-5343504f6f0e.jpeg","brief":"What is a Database Transaction ??!!!!\nA database transaction is a sequence of operations performed as a single logical unit of work. These operations can include creating, reading, updating, or deleting data in a database. The key feature of a transa...","author":"658438ff6397b8f4db0834fe","sB":false,"isRepublished":false,"readTime":11,"draft":"66c5b5f862d77a09589668a1","tags":["66c5c67e554ff2823edbe254","56744722958ef13879b950eb","5eadadcc26e78ca711dfc307","56744723958ef13879b953ed","56744721958ef13879b94b41","56744722958ef13879b94f6f"],"publication":"6584392d6ae26d33cf572bb6","ogImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1724237318496/a4ca2f97-50e5-4b95-b15a-27c52c0ea1af.jpeg","metaTitle":"Understanding Database Transactions with ACID Principles","metaDescription":"Learn how database transactions work with a focus on the ACID principles—Atomicity, Consistency, Isolation, and Durability. Explore a practical example of m","isNewsletterActivated":true,"coAuthors":[],"pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"66c5c67e9daf697a6c8de986"},{"reward":{"type":"xlm"},"githubAsSourceMeta":null,"isAnonymous":false,"coverImage":"","autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"_id":"6587f06c66e4b744e2562538","createdAt":"2023-12-24T08:48:44.540Z","updatedAt":"2023-12-24T08:48:44.540Z","views":113,"isActive":true,"sourcedFromGithub":false,"hasLatex":false,"popularity":6542.145,"discussionScore":0,"enableToc":true,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":true,"disableComments":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"slugOverridden":true,"tweetOptions":{"enabled":false},"title":"Unveiling the Dynamics: A Python Analysis of the Dhaka Stock Market","cuid":"clqj8z854000b08ld3ayg8whm","dateAdded":"2023-12-24T08:48:44.536Z","isCoverAttributionHidden":false,"coverImageAttribution":"","coverImagePhotographer":"","stickCoverToBottom":false,"slug":"dhaka-stock-market-analysis","toc":[[{"id":"dfcae14e-7328-4dfe-bf40-e8f53226ce15","level":3,"previousLevel":null,"parentId":null,"slug":"dataset","title":"Dataset"}],[{"id":"f888d74f-916c-4799-af63-070376d7ab99","level":2,"previousLevel":3,"parentId":null,"slug":"understanding-the-analysis-code","title":"Understanding the Analysis Code"}],[{"id":"ff7be577-b685-459d-bdee-54aad61382e4","level":3,"previousLevel":2,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"import-the-necessary-library","title":"Import the necessary library"}],[{"id":"05e71920-5fe5-45e6-b72c-21661fa91b94","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"loading-the-dataset-with-pandas","title":"Loading the dataset with pandas"}],[{"id":"1af209dd-a252-4855-a9c7-1a33a97c36cc","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"convert-the-date-column-in-the-dataframe-to-a-datetime-format","title":"Convert the 'Date' column in the DataFrame to a DateTime format"}],[{"id":"b05128a2-e710-445f-936b-a5a62326a026","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"calculate-basic-summary-statistics-for-each-column-mean-median-standard-deviation-etc","title":"Calculate basic summary statistics for each column (mean, median, standard deviation, etc.)"}],[{"id":"a36b0e74-f74f-4240-9946-5afa6ddb2d5d","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"selecting-key-companies-from-the-stock-market-dataset","title":"Selecting Key Companies from the Stock Market Dataset"}],[{"id":"557fe2e9-1d29-4861-90a6-881ea4d55f55","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"explore-the-distribution-of-the-close-prices-over-time","title":"Explore the distribution of the 'Close' prices over time"}],[{"id":"c9809f66-7c16-495d-8ffc-f64fa46725e6","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"identify-and-analyze-any-outliers-if-any-in-the-dataset","title":"Identify and analyze any outliers (if any) in the dataset"}],[{"id":"9eef58ba-644b-43ec-aad8-0e6dd9d87b96","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"create-a-line-chart-to-visualize-the-close-prices-over-time","title":"Create a line chart to visualize the 'Close' prices over time"}],[{"id":"3a6c7b56-e5c4-43ae-8eb2-92154cce9209","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"calculate-and-plot-the-daily-percentage-change-in-closing-prices","title":"Calculate and plot the daily percentage change in closing prices"}],[{"id":"f98e5f4a-a21a-4068-ad65-467e1827aab9","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"investigate-the-presence-of-any-trends-or-seasonality-in-the-stock-prices","title":"Investigate the presence of any trends or seasonality in the stock prices"}],[{"id":"7b7fed4a-ba0f-46d1-9441-e72b190d6e77","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"apply-moving-averages-to-smooth-the-time-series-data-in-1530-day-intervals-against-the-original-graph","title":"Apply moving averages to smooth the time series data in 15/30 day intervals against the original graph"}],[{"id":"97c49a20-2129-45ea-be43-e2b551f65c8f","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"111calculate-the-average-closing-price-for-each-stock","title":"11.1.Calculate the average closing price for each stock"}],[{"id":"3964db61-7e0b-468e-8b42-10f5e74b2cad","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"identify-the-top-5-stocks-based-on-the-average-closing-price","title":"Identify the top 5 stocks based on the average closing price"}],[{"id":"ae507650-65ca-40e8-84e4-dda69f5ab4b6","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"identify-the-bottom-5-stocks-based-on-the-average-closing-price","title":"Identify the bottom 5 stocks based on the average closing price"}],[{"id":"4905cf65-27b0-495d-88fb-7622e8acba56","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"calculate-and-plot-the-rolling-standard-deviation-of-the-close-prices","title":"Calculate and plot the rolling standard deviation of the 'Close' prices"}],[{"id":"c5916fe3-06e3-45be-9178-58f8fb809f47","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"daily-price-change-close-open","title":"Daily price change (Close - Open)"}],[{"id":"1c2324fc-6b7d-4805-b6df-85da5134f7a6","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"analyze-the-distribution-of-daily-price-changes","title":"Analyze the distribution of daily price changes"}],[{"id":"516b2e5b-d6d8-4d91-83be-70aaab34d593","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"identify-days-with-the-largest-price-increases-and-decreases","title":"Identify days with the largest price increases and decreases"}],[{"id":"65be1578-62ea-4832-8f02-450953cbc197","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"identify-stocks-with-unusually-high-trading-volume-on-certain-days","title":"Identify stocks with unusually high trading volume on certain days"}],[{"id":"ef7aa572-b1bb-4459-b580-3f7b0719beb4","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"explore-the-relationship-between-trading-volume-and-volatility","title":"Explore the relationship between trading volume and volatility"}],[{"id":"f4e5663c-fee5-4aee-af12-4b5ed877080a","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"correlation-matrix-between-the-open-amp-high-low-ampclose-prices","title":"Correlation matrix between the 'Open' &amp; 'High', 'Low' &amp;'Close' prices"}],[{"id":"34856603-f568-4085-9069-fc5ac2659df7","level":3,"previousLevel":3,"parentId":"f888d74f-916c-4799-af63-070376d7ab99","slug":"heatmap-to-visualize-the-correlations-using-the-seaborn-package","title":"Heatmap to visualize the correlations using the seaborn package"}]],"content":"<hr />\n<p>Welcome to the world of Dhaka stock market analysis! In this blog, we'll delve into the fascinating realm of stock market trends, data analysis, and insights specific to the Dhaka stock market. Through the lens of Python and Jupyter-notebook, we'll uncover valuable information and gain a deeper understanding of the dynamics driving the Dhaka stock market. Join me on this insightful journey as we explore the intricacies of stock market analysis and its implications for investors and enthusiasts alike.</p>\n<h3 id=\"heading-dataset\">Dataset</h3>\n<hr />\n<p>Here is the stock market dataset for your analysis:</p>\n<p><a target=\"_blank\" href=\"https://www.kaggle.com/datasets/tanvirrahmanornob/stock-market-data\">Dhaka Stock Market Dataset</a></p>\n<p>Feel free to explore this comprehensive dataset to gain valuable insights into the dynamics of the Dhaka stock market.</p>\n<h2 id=\"heading-understanding-the-analysis-code\">Understanding the Analysis Code</h2>\n<hr />\n<p>Let's Explain the code block by block</p>\n<ol>\n<li><h3 id=\"heading-import-the-necessary-library\">Import the necessary library</h3>\n<hr />\n<p> These imported libraries are fundamental for the analysis</p>\n<ul>\n<li><p><strong>numpy</strong>: Used for numerical operations and array manipulations.</p>\n</li>\n<li><p><strong>pandas</strong>: Essential for data manipulation and analysis, providing</p>\n<p>  powerful data structures and tools.</p>\n</li>\n<li><p><strong>matplotlib.pyplot</strong>: Enables the creation of visualizations such as plots, charts, and graphs.</p>\n</li>\n<li><p><strong>seaborn</strong>: A powerful library for statistical data visualization, enhancing the aesthetics and overall appeal of visualizations.</p>\n</li>\n</ul>\n</li>\n</ol>\n<pre><code class=\"lang-python\"><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt\n<span class=\"hljs-keyword\">import</span> seaborn <span class=\"hljs-keyword\">as</span> sns\n</code></pre>\n<ol>\n<li><h3 id=\"heading-loading-the-dataset-with-pandas\">Loading the dataset with pandas</h3>\n<hr />\n<p> In this section, the stock market data is imported into the Jupyter-notebook using the <strong>read_csv()</strong> function from the pandas library. Subsequently, the <strong>head()</strong> function is utilized to display the initial rows of the dataset, offering a glimpse into the structure and contents of the Dhaka stock market data</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\">df = pd.read_csv(<span class=\"hljs-string\">\"../input/stock-market-data/Stock_Market_Data.csv\"</span>)\ndf.head()\n</code></pre>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703400805954/73e52698-c7ab-4acb-a60d-dc13b022de00.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-convert-the-date-column-in-the-dataframe-to-a-datetime-format\">Convert the 'Date' column in the DataFrame to a DateTime format</h3>\n<hr />\n<p> This line of code converts the 'Date' column in the stock_data DataFrame to a DateTime format, with the 'dayfirst' parameter set to True. This conversion is essential for time-series analysis and ensures that the date data is interpreted accurately within the analysis.</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\">stock_data[<span class=\"hljs-string\">'Date'</span>] = pd.to_datetime(stock_data[<span class=\"hljs-string\">'Date'</span>],dayfirst=<span class=\"hljs-literal\">True</span>)\n</code></pre>\n<ol>\n<li><h3 id=\"heading-calculate-basic-summary-statistics-for-each-column-mean-median-standard-deviation-etc\">Calculate basic summary statistics for each column (mean, median, standard deviation, etc.)</h3>\n<hr />\n<p> The code computes the summary statistics for the stock_data DataFrame using the <strong>describe()</strong> function, providing key statistical metrics such as <strong>count, mean, standard deviation, and minimum</strong>, and <strong>maximum</strong> values for each numerical column in the dataset.</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\">summ_stat = stock_data.describe()\nsumm_stat\n</code></pre>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703401186722/87c7f01b-921f-4552-ac30-028e68c5a411.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-selecting-key-companies-from-the-stock-market-dataset\">Selecting Key Companies from the Stock Market Dataset</h3>\n<hr />\n<p> With so many companies in the dataset, I'll handpick a selection to dive into. This way, we can really get to know these companies and understand their impact on the market as a whole. You can find all the company names with this code.</p>\n<pre><code class=\"lang-python\"> df[<span class=\"hljs-string\">'Name'</span>].unique()\n</code></pre>\n<p> I have selected five companies below.</p>\n<pre><code class=\"lang-python\"> <span class=\"hljs-comment\">## randomly select 5 company</span>\n unique_names = [<span class=\"hljs-string\">'01.Bank'</span>, <span class=\"hljs-string\">'02.Cement'</span>, <span class=\"hljs-string\">'03.Ceramics_Sector'</span>, <span class=\"hljs-string\">'04.Engineering'</span>,\n        <span class=\"hljs-string\">'05.Financial_Institutions'</span>]\n</code></pre>\n</li>\n<li><h3 id=\"heading-explore-the-distribution-of-the-close-prices-over-time\">Explore the distribution of the 'Close' prices over time</h3>\n<hr />\n<p> This code iterates through unique company names in the dataset, creates individual data for each company, and then generates a histogram of the closing prices over time for each company. It will show a total of 5 companies. two of them are given below The resulting visualizations offer a clear depiction of the distribution of close prices for the selected companies, enabling a comparative analysis of their stock performance.</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\"><span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> unique_names:\n    company_data = stock_data[stock_data[<span class=\"hljs-string\">'Name'</span>] == name]\n    plt.figure(figsize=(<span class=\"hljs-number\">15</span>,<span class=\"hljs-number\">5</span>))\n    sns.histplot(data=company_data ,x=<span class=\"hljs-string\">\"Close\"</span>,bins=<span class=\"hljs-number\">30</span>,label=name)\n    plt.xlabel(<span class=\"hljs-string\">\"Closing Price Distribution\"</span>)\n    plt.ylabel(<span class=\"hljs-string\">\"Frequency\"</span>)\n    plt.title(<span class=\"hljs-string\">\"Distribution of Close Prices Over Time of {}\"</span>.format(name))\n    plt.legend()\n    plt.xticks(rotation=<span class=\"hljs-number\">45</span>)\n    plt.show()\n</code></pre>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703402035713/14f9fa80-d8f4-4262-8977-e6c176cbcbda.png\" alt class=\"image--center mx-auto\" /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703402088321/373d3c2d-6b52-4205-b4db-384da1d531ce.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-identify-and-analyze-any-outliers-if-any-in-the-dataset\">Identify and analyze any outliers (if any) in the dataset</h3>\n<hr />\n<p> This code iterates through unique company names in the dataset, creates individual data for each company, and then generates box plots to visualize the distribution of numerical variables, showcasing any potential outliers for each company. These visualizations provide valuable insights into the spread and potential anomalies within the data for the selected companies.</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\"><span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> unique_names:\n    company_data = stock_data[stock_data[<span class=\"hljs-string\">'Name'</span>]==name]\n    plt.figure(figsize=(<span class=\"hljs-number\">15</span>,<span class=\"hljs-number\">5</span>))\n    sns.boxplot(data=company_data.select_dtypes(include=np.number))\n    plt.title(<span class=\"hljs-string\">f'Box Plots for <span class=\"hljs-subst\">{name}</span> - Outliers'</span>)\n    plt.legend()\n    plt.xticks(rotation=<span class=\"hljs-number\">45</span>)\n    plt.show()\n</code></pre>\n<p>Output (2 out of 5)</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703402377487/f5b325e2-fa65-44f0-bc10-b2cf91397dd6.png\" alt class=\"image--center mx-auto\" /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703402394339/ec448d1e-5ed9-42cf-86fa-e0c10a301bce.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-create-a-line-chart-to-visualize-the-close-prices-over-time\">Create a line chart to visualize the 'Close' prices over time</h3>\n<hr />\n<p> This code iterates through unique company names in the dataset, creates individual data for each company, and then generates line plots to visualize the trend of closing prices over time for each company. These visualizations offer a clear representation of how the closing prices have evolved for the selected companies, providing insights into their historical performance.</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\"><span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> unique_names:\n    company_data = stock_data[stock_data[<span class=\"hljs-string\">'Name'</span>] == name]\n    plt.figure(figsize=(<span class=\"hljs-number\">15</span>, <span class=\"hljs-number\">4</span>))\n    plt.plot(company_data[<span class=\"hljs-string\">'Date'</span>],company_data[<span class=\"hljs-string\">'Close'</span>],label =<span class=\"hljs-string\">\"{}\"</span>.format(name))\n    plt.xlabel(<span class=\"hljs-string\">'Date'</span>)\n    plt.ylabel(<span class=\"hljs-string\">'Closing Price'</span>)\n    plt.title(<span class=\"hljs-string\">'Close Prices Over Time of {}'</span>.format(name))\n    plt.legend()\n    plt.xticks(rotation=<span class=\"hljs-number\">45</span>)\n    plt.show()\n</code></pre>\n<p>Output (2 out of 5)</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703403038848/29cb13b2-177b-4348-bd2e-410f97d46cfa.png\" alt class=\"image--center mx-auto\" /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703403052756/5b39bddf-bc17-428b-be41-2091c250fe4d.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-calculate-and-plot-the-daily-percentage-change-in-closing-prices\">Calculate and plot the daily percentage change in closing prices</h3>\n<hr />\n<p> This code iterates through unique company names in the dataset, calculates the daily percentage change in closing prices for each company, and then generates line plots to visualize these changes over time. These visualizations offer insights into the daily fluctuations in closing prices for the selected companies, aiding in the assessment of their market volatility and performance.</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\"><span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> unique_names:\n    plt.figure(figsize=(<span class=\"hljs-number\">15</span>, <span class=\"hljs-number\">4</span>))\n    company_data = stock_data[stock_data[<span class=\"hljs-string\">'Name'</span>] == name]\n    company_data[<span class=\"hljs-string\">'Daily_PCT_Change'</span>] = company_data[<span class=\"hljs-string\">'Close'</span>].pct_change() * <span class=\"hljs-number\">100</span>\n    plt.plot(company_data[<span class=\"hljs-string\">'Date'</span>], company_data[<span class=\"hljs-string\">'Daily_PCT_Change'</span>], label=name)\n    plt.xlabel(<span class=\"hljs-string\">'Date'</span>)\n    plt.ylabel(<span class=\"hljs-string\">'Daily Percentage Change'</span>)\n    plt.title(<span class=\"hljs-string\">'Daily Percentage Change in Closing Prices of {}'</span>.format(name))\n    plt.legend()\n    plt.xticks(rotation=<span class=\"hljs-number\">45</span>)\n    plt.show()\n</code></pre>\n<p>Output (2 out of 5)</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703403474936/dcc65bd9-980a-4ad3-a1f0-1a595fd3590a.png\" alt class=\"image--center mx-auto\" /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703403490050/b6a95ddc-92eb-47cc-8218-07e1b15a36da.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-investigate-the-presence-of-any-trends-or-seasonality-in-the-stock-prices\">Investigate the presence of any trends or seasonality in the stock prices</h3>\n<hr />\n<p> This code iterates through unique company names in the dataset, plots the closing prices over time for each company, and overlays a rolling average (e.g., 30 days) to visualize the trend. These visualizations provide insights into both the daily fluctuations and the long-term trends in closing prices for the selected companies, aiding in the assessment of their stock performance.</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\"><span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> unique_names:\n    company_data = stock_data[stock_data[<span class=\"hljs-string\">'Name'</span>] == name]\n    plt.plot(company_data[<span class=\"hljs-string\">'Date'</span>],company_data[<span class=\"hljs-string\">'Close'</span>], label=name)\n    <span class=\"hljs-comment\"># Plotting a rolling average (e.g., 30 days) for trend visualization</span>\n    rolling_avg = company_data[<span class=\"hljs-string\">'Close'</span>].rolling(window=<span class=\"hljs-number\">30</span>).mean()\n    plt.plot(company_data[<span class=\"hljs-string\">'Date'</span>],rolling_avg, label=<span class=\"hljs-string\">f'<span class=\"hljs-subst\">{name}</span> - Trend Line'</span>, linestyle=<span class=\"hljs-string\">'--'</span>)\n    plt.title(<span class=\"hljs-string\">'Stock Prices Trend Line Over Time'</span>)\n    plt.xlabel(<span class=\"hljs-string\">'Date'</span>)\n    plt.ylabel(<span class=\"hljs-string\">'Closing Price'</span>)\n    plt.legend()\n    plt.show()\n</code></pre>\n<p>Output (2 out of 5)</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703403671789/ae594480-5e5e-48fd-bf37-c000b698b74f.png\" alt class=\"image--center mx-auto\" /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703403684400/f5e38fb8-c493-4e2c-9b7c-66d747e4bc58.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-apply-moving-averages-to-smooth-the-time-series-data-in-1530-day-intervals-against-the-original-graph\">Apply moving averages to smooth the time series data in 15/30 day intervals against the original graph</h3>\n<hr />\n<p> This code iterates through unique company names in the dataset, calculates the 15-day and 30-day moving averages for each company's closing prices, and then generates visualizations to compare the original closing prices with their respective moving averages over time. These visualizations offer insights into the trend and direction of the stock prices for the selected companies, aiding in the analysis of their historical performance.</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\"><span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> unique_names:\n    plt.figure(figsize=(<span class=\"hljs-number\">15</span>, <span class=\"hljs-number\">5</span>))\n    company_data = stock_data[stock_data[<span class=\"hljs-string\">'Name'</span>] == name]\n    company_data[<span class=\"hljs-string\">'15_Day_MA'</span>] = company_data[<span class=\"hljs-string\">'Close'</span>].rolling(window=<span class=\"hljs-number\">15</span>).mean()\n    company_data[<span class=\"hljs-string\">'30_Day_MA'</span>] = company_data[<span class=\"hljs-string\">'Close'</span>].rolling(window=<span class=\"hljs-number\">30</span>).mean()\n\n    <span class=\"hljs-comment\"># Plotting for the current company</span>\n    plt.plot(company_data[<span class=\"hljs-string\">'Date'</span>], company_data[<span class=\"hljs-string\">'Close'</span>], label=<span class=\"hljs-string\">f'Original Close - <span class=\"hljs-subst\">{name}</span>'</span>,color=<span class=\"hljs-string\">\"red\"</span>)\n    plt.plot(company_data[<span class=\"hljs-string\">'Date'</span>], company_data[<span class=\"hljs-string\">'15_Day_MA'</span>], label=<span class=\"hljs-string\">f'15-Day MA - <span class=\"hljs-subst\">{name}</span>'</span>, linestyle=<span class=\"hljs-string\">'--'</span>,color=<span class=\"hljs-string\">\"blue\"</span>)\n    plt.plot(company_data[<span class=\"hljs-string\">'Date'</span>], company_data[<span class=\"hljs-string\">'30_Day_MA'</span>], label=<span class=\"hljs-string\">f'30-Day MA - <span class=\"hljs-subst\">{name}</span>'</span>, linestyle=<span class=\"hljs-string\">'--'</span>,color=<span class=\"hljs-string\">\"green\"</span>)\n    plt.xlabel(<span class=\"hljs-string\">'Date'</span>)\n    plt.ylabel(<span class=\"hljs-string\">'Close Price'</span>)\n    plt.title(<span class=\"hljs-string\">'Original Time Series with Moving Averages {}'</span>.format(name))\n    plt.legend()\n    plt.show()\n</code></pre>\n<p>Output (2 out of 5)</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703403857956/234c8abe-69fb-44dc-8301-25bee7b912e0.png\" alt class=\"image--center mx-auto\" /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703403872213/2b8a1202-0f73-47af-b1da-9922535e3078.png\" alt class=\"image--center mx-auto\" /></p>\n<h3 id=\"heading-111calculate-the-average-closing-price-for-each-stock\">11.1.Calculate the average closing price for each stock</h3>\n<hr />\n<p>The code creates a new DataFrame, '<strong>df</strong>', by calculating the average closing price for each company from the 'stock_data' DataFrame using the '<strong>groupby()</strong>' function. The resulting DataFrame contains two columns: '<strong>Name</strong>' and '<strong>AvgClosingPrice</strong>', displaying the average closing price for each company.</p>\n<pre><code class=\"lang-python\">df = pd.DataFrame(stock_data.groupby(<span class=\"hljs-string\">'Name'</span>)[<span class=\"hljs-string\">'Close'</span>].mean()).reset_index()\ndf.columns=[<span class=\"hljs-string\">'Name'</span>,<span class=\"hljs-string\">'AvgClosingPrice'</span>]\ndf.head()\n</code></pre>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703404061659/099b7fcc-21f3-4443-9461-caff83cd11dd.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-identify-the-top-5-stocks-based-on-the-average-closing-price\">Identify the top 5 stocks based on the average closing price</h3>\n<hr />\n</li>\n</ol>\n<pre><code class=\"lang-python\">df_sorted = df.sort_values(by=<span class=\"hljs-string\">'AvgClosingPrice'</span>,ascending=<span class=\"hljs-literal\">False</span>)\ntop5 = df_sorted.head(<span class=\"hljs-number\">5</span>)\ntop5\n</code></pre>\n<ol>\n<li><h3 id=\"heading-identify-the-bottom-5-stocks-based-on-the-average-closing-price\">Identify the bottom 5 stocks based on the average closing price</h3>\n<hr />\n</li>\n</ol>\n<pre><code class=\"lang-python\">df_sorted = df.sort_values(by=<span class=\"hljs-string\">'AvgClosingPrice'</span>,ascending=<span class=\"hljs-literal\">False</span>)\nbottom5 = df_sorted.tail(<span class=\"hljs-number\">5</span>)\nbottom5\n</code></pre>\n<ol>\n<li><h3 id=\"heading-calculate-and-plot-the-rolling-standard-deviation-of-the-close-prices\">Calculate and plot the rolling standard deviation of the 'Close' prices</h3>\n<hr />\n<p> The code iterates through unique company names, retrieves stock data for each company, and creates a plot showing the rolling standard deviation of their closing prices over time using a 30-day window. This visualization helps compare the volatility of stock prices among different companies.</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\"><span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> unique_names:\n    company_data = stock_data[stock_data[<span class=\"hljs-string\">'Name'</span>] == name]\n    plt.figure(figsize=(<span class=\"hljs-number\">15</span>, <span class=\"hljs-number\">8</span>))\n    rolling_std = company_data[<span class=\"hljs-string\">'Close'</span>].rolling(window=<span class=\"hljs-number\">30</span>).std()\n    plt.plot(company_data[<span class=\"hljs-string\">'Date'</span>],rolling_std, label=<span class=\"hljs-string\">f'Rolling Std (30 days) - <span class=\"hljs-subst\">{name}</span>'</span>,linestyle=<span class=\"hljs-string\">'--'</span>,color=<span class=\"hljs-string\">\"blue\"</span>)\n    plt.xlabel(<span class=\"hljs-string\">'Date'</span>)\n    plt.ylabel(<span class=\"hljs-string\">'Rolling Standard Deviation'</span>)\n    plt.title(<span class=\"hljs-string\">'Rolling Standard Deviation of Close Prices for Each Company'</span>)\n    plt.legend()\n    plt.xticks(rotation=<span class=\"hljs-number\">45</span>)\n    plt.show()\n</code></pre>\n<p>Output(2 out of 5)</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703404817653/0a86b821-8f0e-4c84-b770-a308b2cf26f5.png\" alt class=\"image--center mx-auto\" /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703404836053/ae1fcb78-707c-4bae-9a9a-bb43b05b200c.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-daily-price-change-close-open\">Daily price change (Close - Open)</h3>\n<hr />\n</li>\n</ol>\n<pre><code class=\"lang-python\">stock_data[<span class=\"hljs-string\">'daily_price_change'</span>] = stock_data[<span class=\"hljs-string\">'Close'</span>] - stock_data[<span class=\"hljs-string\">'Open'</span>]\nstock_data.head()\n</code></pre>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703405715699/6a35e75c-b1e9-477b-b694-1c88874c2805.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-analyze-the-distribution-of-daily-price-changes\">Analyze the distribution of daily price changes</h3>\n<hr />\n<p> This code iterates through unique company names, retrieves stock data for each company, and creates a histogram showing the distribution of daily price changes over time for each company. The Seaborn library is used to generate the histograms, with each company's data represented by a different color. The visualization provides an overview of the frequency and distribution of daily price changes for each company.</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\"><span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> unique_names:\n    company_data = stock_data[stock_data[<span class=\"hljs-string\">'Name'</span>] == name]\n    sns.histplot(data=company_data, x=<span class=\"hljs-string\">'daily_price_change'</span>, bins=<span class=\"hljs-number\">30</span>, label=name)\n    plt.xlabel(<span class=\"hljs-string\">'Daily Price Chnage'</span>)\n    plt.ylabel(<span class=\"hljs-string\">'Frequency'</span>)\n    plt.title(<span class=\"hljs-string\">'Distribution of Daily Price Chnage Over Time {}'</span>.format(name))\n    plt.legend()\n    plt.show()\n</code></pre>\n<p>Output(2 out of 5)</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703405913076/3f25b2ba-15b0-4885-a565-38d668e9d01f.png\" alt class=\"image--center mx-auto\" /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703405933699/ee3c86d3-5183-4fe3-952b-3e2fae39ba36.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-identify-days-with-the-largest-price-increases-and-decreases\">Identify days with the largest price increases and decreases</h3>\n<hr />\n</li>\n</ol>\n<pre><code class=\"lang-python\">sorted_data = stock_data.sort_values(<span class=\"hljs-string\">\"daily_price_change\"</span>,ascending=<span class=\"hljs-literal\">False</span>)\nlargest_price_increase = sorted_data.head(<span class=\"hljs-number\">1</span>)\nlargest_price_increase\n</code></pre>\n<pre><code class=\"lang-python\">sorted_data = stock_data.sort_values(<span class=\"hljs-string\">\"daily_price_change\"</span>,ascending=<span class=\"hljs-literal\">False</span>)\nlargest_price_decrease = sorted_data.tail(<span class=\"hljs-number\">1</span>)\nlargest_price_decrease\n</code></pre>\n<ol>\n<li><h3 id=\"heading-identify-stocks-with-unusually-high-trading-volume-on-certain-days\">Identify stocks with unusually high trading volume on certain days</h3>\n<hr />\n<p> This code iterates through unique company names, retrieves stock data for each company, and creates a plot showing the trading volume over time. It also highlights unusually high volume days with red markers. The visualization aims to emphasize and compare the trading volume patterns for different companies, particularly focusing on days with exceptionally high trading volume</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\"><span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> unique_names:\n    company_data = stock_data[stock_data[<span class=\"hljs-string\">'Name'</span>] == name]\n    plt.plot(company_data[<span class=\"hljs-string\">'Date'</span>],company_data[<span class=\"hljs-string\">'Volume'</span>],label=name)\n    threshold = company_data[<span class=\"hljs-string\">'Volume'</span>].quantile(<span class=\"hljs-number\">0.95</span>)\n    high_volume_data = company_data[company_data[<span class=\"hljs-string\">'Volume'</span>] &gt; threshold]\n    plt.scatter(high_volume_data[<span class=\"hljs-string\">'Date'</span>],high_volume_data[<span class=\"hljs-string\">'Volume'</span>],color=<span class=\"hljs-string\">\"red\"</span>,marker=<span class=\"hljs-string\">'o'</span>,label=<span class=\"hljs-string\">\"{} - High Volume Days\"</span>.format(name))\n    plt.title(<span class=\"hljs-string\">'Trading Volume Over Time with Emphasis on Unusually High Volume Days'</span>)\n    plt.xlabel(<span class=\"hljs-string\">'Date'</span>)\n    plt.ylabel(<span class=\"hljs-string\">'Trading Volume'</span>)\n    plt.legend()\n    plt.show()\n</code></pre>\n<p>Output (2 out of 5)</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703406456664/153957ee-1cf9-4476-96a1-fd1ad2bbecaa.png\" alt class=\"image--center mx-auto\" /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703406472607/1e1d7f4e-5cc5-469e-9052-95eb57e3859a.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-explore-the-relationship-between-trading-volume-and-volatility\">Explore the relationship between trading volume and volatility</h3>\n<hr />\n<p> This code calculates the volatility of stock prices and creates a correlation heatmap for each company. It first calculates the volatility as the percentage change in closing prices and then computes the correlation between volume and volatility for each company. Subsequently, it generates a series of correlation heatmaps, one for each company, to visualize the relationship between trading volume and stock price volatility.</p>\n</li>\n</ol>\n<pre><code class=\"lang-python\">stock_data[<span class=\"hljs-string\">'Volatility'</span>] = stock_data.groupby(<span class=\"hljs-string\">\"Name\"</span>)[<span class=\"hljs-string\">'Close'</span>].pct_change()\ncorrelation_matrix = stock_data.groupby(<span class=\"hljs-string\">\"Name\"</span>)[[<span class=\"hljs-string\">'Volume'</span>,<span class=\"hljs-string\">'Volatility'</span>]].corr()\n<span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> unique_names:\n    plt.figure(figsize=(<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">4</span>))\n    sns.heatmap(correlation_matrix.loc[name],annot=<span class=\"hljs-literal\">True</span>)\n    plt.title(<span class=\"hljs-string\">\"Correlation Heatmap of {}\"</span>.format(name))\n    plt.show()\n</code></pre>\n<p>Output (2 out of 5)</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703406803274/60534b8d-43fd-41a7-8972-c329495915f3.png\" alt class=\"image--center mx-auto\" /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703406818889/0cf2e6eb-7a43-4bc4-8ded-d0b271c9995f.png\" alt class=\"image--center mx-auto\" /></p>\n<ol>\n<li><h3 id=\"heading-correlation-matrix-between-the-open-amp-high-low-ampclose-prices\">Correlation matrix between the 'Open' &amp; 'High', 'Low' &amp;'Close' prices</h3>\n<hr />\n</li>\n</ol>\n<pre><code class=\"lang-python\">price_columns = [<span class=\"hljs-string\">'Open'</span>, <span class=\"hljs-string\">'High'</span>, <span class=\"hljs-string\">'Low'</span>, <span class=\"hljs-string\">'Close'</span>]\n\n<span class=\"hljs-comment\"># Group by 'Name' and calculate the correlation matrix for each group</span>\ncorrelation_matrices = stock_data.groupby(<span class=\"hljs-string\">'Name'</span>)[price_columns].corr()\n<span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> unique_names:\n    print(<span class=\"hljs-string\">\"Company Name : {}\"</span>.format(name))\n    print(<span class=\"hljs-string\">\"-\"</span>*<span class=\"hljs-number\">50</span>)\n    print(correlation_matrices.loc[name])\n    print(<span class=\"hljs-string\">\"-\"</span>*<span class=\"hljs-number\">50</span>)\n</code></pre>\n<ol>\n<li><h3 id=\"heading-heatmap-to-visualize-the-correlations-using-the-seaborn-package\">Heatmap to visualize the correlations using the seaborn package</h3>\n<hr />\n</li>\n</ol>\n<pre><code class=\"lang-python\"><span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> unique_names:\n    plt.figure(figsize=(<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">4</span>))\n    sns.heatmap(correlation_matrices.loc[name],annot=<span class=\"hljs-literal\">True</span>)\n    plt.title(<span class=\"hljs-string\">\"Correlation Heatmap of {}\"</span>.format(name))\n    plt.show()\n</code></pre>\n<p>Output(2 out of 5)</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703407099030/503fbd09-0063-4b47-82d4-ef9909438847.png\" alt class=\"image--center mx-auto\" /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1703407123766/7f8c9a8a-fceb-4701-b0ef-6d69a0f5034a.png\" alt class=\"image--center mx-auto\" /></p>\n","contentMarkdown":"---\n\nWelcome to the world of Dhaka stock market analysis! In this blog, we'll delve into the fascinating realm of stock market trends, data analysis, and insights specific to the Dhaka stock market. Through the lens of Python and Jupyter-notebook, we'll uncover valuable information and gain a deeper understanding of the dynamics driving the Dhaka stock market. Join me on this insightful journey as we explore the intricacies of stock market analysis and its implications for investors and enthusiasts alike.\n\n### Dataset\n\n---\n\nHere is the stock market dataset for your analysis:\n\n[Dhaka Stock Market Dataset](https://www.kaggle.com/datasets/tanvirrahmanornob/stock-market-data)\n\nFeel free to explore this comprehensive dataset to gain valuable insights into the dynamics of the Dhaka stock market.\n\n## Understanding the Analysis Code\n\n---\n\nLet's Explain the code block by block\n\n1. ### Import the necessary library\n    \n    ---\n    \n    These imported libraries are fundamental for the analysis\n    \n    * **numpy**: Used for numerical operations and array manipulations.\n        \n    * **pandas**: Essential for data manipulation and analysis, providing\n        \n        powerful data structures and tools.\n        \n    * **matplotlib.pyplot**: Enables the creation of visualizations such as plots, charts, and graphs.\n        \n    * **seaborn**: A powerful library for statistical data visualization, enhancing the aesthetics and overall appeal of visualizations.\n        \n    \n\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n\n1. ### Loading the dataset with pandas\n    \n    ---\n    \n    In this section, the stock market data is imported into the Jupyter-notebook using the **read\\_csv()** function from the pandas library. Subsequently, the **head()** function is utilized to display the initial rows of the dataset, offering a glimpse into the structure and contents of the Dhaka stock market data\n    \n\n```python\ndf = pd.read_csv(\"../input/stock-market-data/Stock_Market_Data.csv\")\ndf.head()\n```\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703400805954/73e52698-c7ab-4acb-a60d-dc13b022de00.png align=\"center\")\n\n1. ### Convert the 'Date' column in the DataFrame to a DateTime format\n    \n    ---\n    \n    This line of code converts the 'Date' column in the stock\\_data DataFrame to a DateTime format, with the 'dayfirst' parameter set to True. This conversion is essential for time-series analysis and ensures that the date data is interpreted accurately within the analysis.\n    \n\n```python\nstock_data['Date'] = pd.to_datetime(stock_data['Date'],dayfirst=True)\n```\n\n1. ### Calculate basic summary statistics for each column (mean, median, standard deviation, etc.)\n    \n    ---\n    \n    The code computes the summary statistics for the stock\\_data DataFrame using the **describe()** function, providing key statistical metrics such as **count, mean, standard deviation, and minimum**, and **maximum** values for each numerical column in the dataset.\n    \n\n```python\nsumm_stat = stock_data.describe()\nsumm_stat\n```\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703401186722/87c7f01b-921f-4552-ac30-028e68c5a411.png align=\"center\")\n\n1. ### Selecting Key Companies from the Stock Market Dataset\n    \n    ---\n    \n    With so many companies in the dataset, I'll handpick a selection to dive into. This way, we can really get to know these companies and understand their impact on the market as a whole. You can find all the company names with this code.\n    \n    ```python\n    df['Name'].unique() \n    ```\n    \n    I have selected five companies below.\n    \n    ```python\n    ## randomly select 5 company\n    unique_names = ['01.Bank', '02.Cement', '03.Ceramics_Sector', '04.Engineering',\n           '05.Financial_Institutions']\n    ```\n    \n2. ### Explore the distribution of the 'Close' prices over time\n    \n    ---\n    \n    This code iterates through unique company names in the dataset, creates individual data for each company, and then generates a histogram of the closing prices over time for each company. It will show a total of 5 companies. two of them are given below The resulting visualizations offer a clear depiction of the distribution of close prices for the selected companies, enabling a comparative analysis of their stock performance.\n    \n\n```python\nfor name in unique_names:\n    company_data = stock_data[stock_data['Name'] == name]\n    plt.figure(figsize=(15,5))\n    sns.histplot(data=company_data ,x=\"Close\",bins=30,label=name)\n    plt.xlabel(\"Closing Price Distribution\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Distribution of Close Prices Over Time of {}\".format(name))\n    plt.legend()\n    plt.xticks(rotation=45)\n    plt.show()\n```\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703402035713/14f9fa80-d8f4-4262-8977-e6c176cbcbda.png align=\"center\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703402088321/373d3c2d-6b52-4205-b4db-384da1d531ce.png align=\"center\")\n\n1. ### Identify and analyze any outliers (if any) in the dataset\n    \n    ---\n    \n    This code iterates through unique company names in the dataset, creates individual data for each company, and then generates box plots to visualize the distribution of numerical variables, showcasing any potential outliers for each company. These visualizations provide valuable insights into the spread and potential anomalies within the data for the selected companies.\n    \n\n```python\nfor name in unique_names:\n    company_data = stock_data[stock_data['Name']==name]\n    plt.figure(figsize=(15,5))\n    sns.boxplot(data=company_data.select_dtypes(include=np.number))\n    plt.title(f'Box Plots for {name} - Outliers')\n    plt.legend()\n    plt.xticks(rotation=45)\n    plt.show()\n```\n\nOutput (2 out of 5)\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703402377487/f5b325e2-fa65-44f0-bc10-b2cf91397dd6.png align=\"center\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703402394339/ec448d1e-5ed9-42cf-86fa-e0c10a301bce.png align=\"center\")\n\n1. ### Create a line chart to visualize the 'Close' prices over time\n    \n    ---\n    \n    This code iterates through unique company names in the dataset, creates individual data for each company, and then generates line plots to visualize the trend of closing prices over time for each company. These visualizations offer a clear representation of how the closing prices have evolved for the selected companies, providing insights into their historical performance.\n    \n\n```python\nfor name in unique_names:\n    company_data = stock_data[stock_data['Name'] == name]\n    plt.figure(figsize=(15, 4))\n    plt.plot(company_data['Date'],company_data['Close'],label =\"{}\".format(name))\n    plt.xlabel('Date')\n    plt.ylabel('Closing Price')\n    plt.title('Close Prices Over Time of {}'.format(name))\n    plt.legend()\n    plt.xticks(rotation=45)\n    plt.show()\n```\n\nOutput (2 out of 5)\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703403038848/29cb13b2-177b-4348-bd2e-410f97d46cfa.png align=\"center\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703403052756/5b39bddf-bc17-428b-be41-2091c250fe4d.png align=\"center\")\n\n1. ### Calculate and plot the daily percentage change in closing prices\n    \n    ---\n    \n    This code iterates through unique company names in the dataset, calculates the daily percentage change in closing prices for each company, and then generates line plots to visualize these changes over time. These visualizations offer insights into the daily fluctuations in closing prices for the selected companies, aiding in the assessment of their market volatility and performance.\n    \n\n```python\nfor name in unique_names:\n    plt.figure(figsize=(15, 4))\n    company_data = stock_data[stock_data['Name'] == name]\n    company_data['Daily_PCT_Change'] = company_data['Close'].pct_change() * 100\n    plt.plot(company_data['Date'], company_data['Daily_PCT_Change'], label=name)\n    plt.xlabel('Date')\n    plt.ylabel('Daily Percentage Change')\n    plt.title('Daily Percentage Change in Closing Prices of {}'.format(name))\n    plt.legend()\n    plt.xticks(rotation=45)\n    plt.show()\n```\n\nOutput (2 out of 5)\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703403474936/dcc65bd9-980a-4ad3-a1f0-1a595fd3590a.png align=\"center\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703403490050/b6a95ddc-92eb-47cc-8218-07e1b15a36da.png align=\"center\")\n\n1. ### Investigate the presence of any trends or seasonality in the stock prices\n    \n    ---\n    \n    This code iterates through unique company names in the dataset, plots the closing prices over time for each company, and overlays a rolling average (e.g., 30 days) to visualize the trend. These visualizations provide insights into both the daily fluctuations and the long-term trends in closing prices for the selected companies, aiding in the assessment of their stock performance.\n    \n\n```python\nfor name in unique_names:\n    company_data = stock_data[stock_data['Name'] == name]\n    plt.plot(company_data['Date'],company_data['Close'], label=name)\n    # Plotting a rolling average (e.g., 30 days) for trend visualization\n    rolling_avg = company_data['Close'].rolling(window=30).mean()\n    plt.plot(company_data['Date'],rolling_avg, label=f'{name} - Trend Line', linestyle='--')\n    plt.title('Stock Prices Trend Line Over Time')\n    plt.xlabel('Date')\n    plt.ylabel('Closing Price')\n    plt.legend()\n    plt.show()\n```\n\nOutput (2 out of 5)\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703403671789/ae594480-5e5e-48fd-bf37-c000b698b74f.png align=\"center\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703403684400/f5e38fb8-c493-4e2c-9b7c-66d747e4bc58.png align=\"center\")\n\n1. ### Apply moving averages to smooth the time series data in 15/30 day intervals against the original graph\n    \n    ---\n    \n    This code iterates through unique company names in the dataset, calculates the 15-day and 30-day moving averages for each company's closing prices, and then generates visualizations to compare the original closing prices with their respective moving averages over time. These visualizations offer insights into the trend and direction of the stock prices for the selected companies, aiding in the analysis of their historical performance.\n    \n\n```python\nfor name in unique_names:\n    plt.figure(figsize=(15, 5))\n    company_data = stock_data[stock_data['Name'] == name]\n    company_data['15_Day_MA'] = company_data['Close'].rolling(window=15).mean()\n    company_data['30_Day_MA'] = company_data['Close'].rolling(window=30).mean()\n\n    # Plotting for the current company\n    plt.plot(company_data['Date'], company_data['Close'], label=f'Original Close - {name}',color=\"red\")\n    plt.plot(company_data['Date'], company_data['15_Day_MA'], label=f'15-Day MA - {name}', linestyle='--',color=\"blue\")\n    plt.plot(company_data['Date'], company_data['30_Day_MA'], label=f'30-Day MA - {name}', linestyle='--',color=\"green\")\n    plt.xlabel('Date')\n    plt.ylabel('Close Price')\n    plt.title('Original Time Series with Moving Averages {}'.format(name))\n    plt.legend()\n    plt.show()\n```\n\nOutput (2 out of 5)\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703403857956/234c8abe-69fb-44dc-8301-25bee7b912e0.png align=\"center\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703403872213/2b8a1202-0f73-47af-b1da-9922535e3078.png align=\"center\")\n\n### 11.1.Calculate the average closing price for each stock\n\n---\n\nThe code creates a new DataFrame, '**df**', by calculating the average closing price for each company from the 'stock\\_data' DataFrame using the '**groupby()**' function. The resulting DataFrame contains two columns: '**Name**' and '**AvgClosingPrice**', displaying the average closing price for each company.\n\n```python\ndf = pd.DataFrame(stock_data.groupby('Name')['Close'].mean()).reset_index()\ndf.columns=['Name','AvgClosingPrice']\ndf.head()\n```\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703404061659/099b7fcc-21f3-4443-9461-caff83cd11dd.png align=\"center\")\n\n1. ### Identify the top 5 stocks based on the average closing price\n    \n    ---\n    \n\n```python\ndf_sorted = df.sort_values(by='AvgClosingPrice',ascending=False)\ntop5 = df_sorted.head(5)\ntop5\n```\n\n1. ### Identify the bottom 5 stocks based on the average closing price\n    \n    ---\n    \n\n```python\ndf_sorted = df.sort_values(by='AvgClosingPrice',ascending=False)\nbottom5 = df_sorted.tail(5)\nbottom5\n```\n\n1. ### Calculate and plot the rolling standard deviation of the 'Close' prices\n    \n    ---\n    \n    The code iterates through unique company names, retrieves stock data for each company, and creates a plot showing the rolling standard deviation of their closing prices over time using a 30-day window. This visualization helps compare the volatility of stock prices among different companies.\n    \n\n```python\nfor name in unique_names:\n    company_data = stock_data[stock_data['Name'] == name]\n    plt.figure(figsize=(15, 8))\n    rolling_std = company_data['Close'].rolling(window=30).std()\n    plt.plot(company_data['Date'],rolling_std, label=f'Rolling Std (30 days) - {name}',linestyle='--',color=\"blue\")\n    plt.xlabel('Date')\n    plt.ylabel('Rolling Standard Deviation')\n    plt.title('Rolling Standard Deviation of Close Prices for Each Company')\n    plt.legend()\n    plt.xticks(rotation=45)\n    plt.show()\n```\n\nOutput(2 out of 5)\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703404817653/0a86b821-8f0e-4c84-b770-a308b2cf26f5.png align=\"center\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703404836053/ae1fcb78-707c-4bae-9a9a-bb43b05b200c.png align=\"center\")\n\n1. ### Daily price change (Close - Open)\n    \n    ---\n    \n\n```python\nstock_data['daily_price_change'] = stock_data['Close'] - stock_data['Open']\nstock_data.head()\n```\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703405715699/6a35e75c-b1e9-477b-b694-1c88874c2805.png align=\"center\")\n\n1. ### Analyze the distribution of daily price changes\n    \n    ---\n    \n    This code iterates through unique company names, retrieves stock data for each company, and creates a histogram showing the distribution of daily price changes over time for each company. The Seaborn library is used to generate the histograms, with each company's data represented by a different color. The visualization provides an overview of the frequency and distribution of daily price changes for each company.\n    \n\n```python\nfor name in unique_names:\n    company_data = stock_data[stock_data['Name'] == name]\n    sns.histplot(data=company_data, x='daily_price_change', bins=30, label=name)\n    plt.xlabel('Daily Price Chnage')\n    plt.ylabel('Frequency')\n    plt.title('Distribution of Daily Price Chnage Over Time {}'.format(name))\n    plt.legend()\n    plt.show()\n```\n\nOutput(2 out of 5)\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703405913076/3f25b2ba-15b0-4885-a565-38d668e9d01f.png align=\"center\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703405933699/ee3c86d3-5183-4fe3-952b-3e2fae39ba36.png align=\"center\")\n\n1. ### Identify days with the largest price increases and decreases\n    \n    ---\n    \n\n```python\nsorted_data = stock_data.sort_values(\"daily_price_change\",ascending=False)\nlargest_price_increase = sorted_data.head(1)\nlargest_price_increase\n```\n\n```python\nsorted_data = stock_data.sort_values(\"daily_price_change\",ascending=False)\nlargest_price_decrease = sorted_data.tail(1)\nlargest_price_decrease\n```\n\n1. ### Identify stocks with unusually high trading volume on certain days\n    \n    ---\n    \n    This code iterates through unique company names, retrieves stock data for each company, and creates a plot showing the trading volume over time. It also highlights unusually high volume days with red markers. The visualization aims to emphasize and compare the trading volume patterns for different companies, particularly focusing on days with exceptionally high trading volume\n    \n\n```python\nfor name in unique_names:\n    company_data = stock_data[stock_data['Name'] == name]\n    plt.plot(company_data['Date'],company_data['Volume'],label=name)\n    threshold = company_data['Volume'].quantile(0.95)\n    high_volume_data = company_data[company_data['Volume'] > threshold]\n    plt.scatter(high_volume_data['Date'],high_volume_data['Volume'],color=\"red\",marker='o',label=\"{} - High Volume Days\".format(name))\n    plt.title('Trading Volume Over Time with Emphasis on Unusually High Volume Days')\n    plt.xlabel('Date')\n    plt.ylabel('Trading Volume')\n    plt.legend()\n    plt.show()\n```\n\nOutput (2 out of 5)\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703406456664/153957ee-1cf9-4476-96a1-fd1ad2bbecaa.png align=\"center\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703406472607/1e1d7f4e-5cc5-469e-9052-95eb57e3859a.png align=\"center\")\n\n1. ### Explore the relationship between trading volume and volatility\n    \n    ---\n    \n    This code calculates the volatility of stock prices and creates a correlation heatmap for each company. It first calculates the volatility as the percentage change in closing prices and then computes the correlation between volume and volatility for each company. Subsequently, it generates a series of correlation heatmaps, one for each company, to visualize the relationship between trading volume and stock price volatility.\n    \n\n```python\nstock_data['Volatility'] = stock_data.groupby(\"Name\")['Close'].pct_change()\ncorrelation_matrix = stock_data.groupby(\"Name\")[['Volume','Volatility']].corr()\nfor name in unique_names:\n    plt.figure(figsize=(4,4))\n    sns.heatmap(correlation_matrix.loc[name],annot=True)\n    plt.title(\"Correlation Heatmap of {}\".format(name))\n    plt.show()\n```\n\nOutput (2 out of 5)\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703406803274/60534b8d-43fd-41a7-8972-c329495915f3.png align=\"center\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703406818889/0cf2e6eb-7a43-4bc4-8ded-d0b271c9995f.png align=\"center\")\n\n1. ### Correlation matrix between the 'Open' & 'High', 'Low' &'Close' prices\n    \n    ---\n    \n\n```python\nprice_columns = ['Open', 'High', 'Low', 'Close']\n\n# Group by 'Name' and calculate the correlation matrix for each group\ncorrelation_matrices = stock_data.groupby('Name')[price_columns].corr()\nfor name in unique_names:\n    print(\"Company Name : {}\".format(name))\n    print(\"-\"*50)\n    print(correlation_matrices.loc[name])\n    print(\"-\"*50)\n```\n\n1. ### Heatmap to visualize the correlations using the seaborn package\n    \n    ---\n    \n\n```python\nfor name in unique_names:\n    plt.figure(figsize=(4,4))\n    sns.heatmap(correlation_matrices.loc[name],annot=True)\n    plt.title(\"Correlation Heatmap of {}\".format(name))\n    plt.show()\n```\n\nOutput(2 out of 5)\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703407099030/503fbd09-0063-4b47-82d4-ef9909438847.png align=\"center\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703407123766/7f8c9a8a-fceb-4701-b0ef-6d69a0f5034a.png align=\"center\")","brief":"Welcome to the world of Dhaka stock market analysis! In this blog, we'll delve into the fascinating realm of stock market trends, data analysis, and insights specific to the Dhaka stock market. Through the lens of Python and Jupyter-notebook, we'll u...","author":"658438ff6397b8f4db0834fe","sB":false,"isRepublished":false,"readTime":9,"draft":"6587c4006b75d36f1ba7fc86","tags":["6587f06c7f2e4b55d0041e45","62c42d87c0401b3dcbd00661","56744723958ef13879b95342","56744723958ef13879b953e6","57c7c7c7e53060955aa8c018","56744722958ef13879b951ac","640819693f7a54eed3e414c3"],"publication":"6584392d6ae26d33cf572bb6","ogImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1703407597477/e20ebba3-d551-4092-b33c-2ea49a91d1e2.jpeg","metaTitle":"Dhaka Stock Market Analysis","metaDescription":"Dhaka stock market analysis! In this blog, we'll delve into the fascinating realm of stock market trends, data analysis, and insight.","isNewsletterActivated":true,"coAuthors":[],"viewsUpdatedOn":1710815432187,"pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"6587f06c66e4b744e2562538"}]}